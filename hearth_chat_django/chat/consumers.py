import json
import os
import uuid
from channels.generic.websocket import AsyncWebsocketConsumer
from dotenv import load_dotenv
from asgiref.sync import sync_to_async

load_dotenv()
from openai import OpenAI

class ChatConsumer(AsyncWebsocketConsumer):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.session_id = None
        self.user_emotion_history = []  # ê°ì • ë³€í™” ì¶”ì 
        self.conversation_context = []  # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì €ì¥
    
    def _force_utf8mb4_connection(self):
        """MySQL ì—°ê²°ì„ ê°•ì œë¡œ utf8mb4ë¡œ ì„¤ì • (ë™ê¸° ë²„ì „)"""
        try:
            from django.db import connections
            connection = connections['default']
            
            if connection.connection is None:
                connection.ensure_connection()
            
            cursor = connection.cursor()
            
            # utf8mb4 ê°•ì œ ì„¤ì •
            utf8mb4_commands = [
                "SET character_set_client=utf8mb4",
                "SET character_set_connection=utf8mb4",
                "SET character_set_results=utf8mb4", 
                "SET collation_connection=utf8mb4_unicode_ci",
                "SET NAMES utf8mb4",
                "SET sql_mode='STRICT_TRANS_TABLES'"
            ]
            
            for command in utf8mb4_commands:
                cursor.execute(command)
            
            cursor.close()
            # print("WebSocket ì—°ê²° ì‹œ MySQL utf8mb4 ê°•ì œ ì„¤ì • ì™„ë£Œ!")
            
        except Exception as e:
            print(f"MySQL utf8mb4 ì„¤ì • ì˜¤ë¥˜: {e}")

    @sync_to_async
    def _force_utf8mb4_connection_async(self):
        """MySQL ì—°ê²°ì„ ê°•ì œë¡œ utf8mb4ë¡œ ì„¤ì • (ë¹„ë™ê¸° ì•ˆì „ ë²„ì „)"""
        return self._force_utf8mb4_connection()

    async def connect(self):
        await self.accept()
        # ì„¸ì…˜ ID ìƒì„±
        self.session_id = str(uuid.uuid4())
        print(f"ìƒˆë¡œìš´ WebSocket ì—°ê²°: {self.session_id}")
        
        # MySQL ì—°ê²°ì„ ê°•ì œë¡œ utf8mb4ë¡œ ì„¤ì • (async contextì—ì„œ ì•ˆì „í•˜ê²Œ)
        await self._force_utf8mb4_connection_async()

    async def disconnect(self, close_code):
        print(f"WebSocket ì—°ê²° ì¢…ë£Œ: {self.session_id}")

    async def receive(self, text_data):
        print("WebSocket ë©”ì‹œì§€ ìˆ˜ì‹ :", text_data)
        if not text_data:
            await self.send(text_data=json.dumps({'message': "ë¹ˆ ë©”ì‹œì§€ëŠ” ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}))
            return
        try:
            data = json.loads(text_data)
        except json.JSONDecodeError:
            await self.send(text_data=json.dumps({'message': "ì˜ëª»ëœ í˜•ì‹ì˜ ë©”ì‹œì§€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œ ë³´ë‚´ì£¼ì„¸ìš”."}))
            return
        
        user_message = data.get("message", "")
        user_emotion = data.get("emotion", "neutral")  # ê°ì • ì •ë³´ ì¶”ì¶œ
        image_url = data.get("imageUrl", "")

        if not user_message and not image_url:
            await self.send(text_data=json.dumps({'message': "ë©”ì‹œì§€ì™€ ì´ë¯¸ì§€ê°€ ëª¨ë‘ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."}))
            return

        # ê°ì • ë³€í™” ì¶”ì 
        self.update_emotion_history(user_emotion)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ DBì— ì €ì¥ (ê°ì • ì •ë³´ í¬í•¨)
        print(f"ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ì‹œë„: {user_message} (ê°ì •: {user_emotion}) ì´ë¯¸ì§€: {image_url}")
        await self.save_user_message(user_message or '[ì´ë¯¸ì§€ ì²¨ë¶€]', user_emotion)

        try:
            print("[DEBUG] get_ai_response í˜¸ì¶œ ì§ì „ (user_message:", user_message, ", user_emotion:", user_emotion, ", image_url:", image_url, ")")
            ai_response = await self.get_ai_response(user_message, user_emotion, image_url)
            print(f"[DEBUG] get_ai_response í˜¸ì¶œ í›„, AI ì‘ë‹µ ë°›ìŒ: {ai_response}")
            
            # AI ì‘ë‹µì„ DBì— ì €ì¥
            print(f"AI ì‘ë‹µ ì €ì¥ ì‹œë„: {ai_response}")
            await self.save_ai_message(ai_response)
            
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            self.conversation_context.append({
                "user": {"message": user_message, "emotion": user_emotion, "image": image_url},
                "ai": {"message": ai_response}
            })
            
            # ì»¨í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ìµœê·¼ 10ê°œë§Œ ìœ ì§€
            if len(self.conversation_context) > 10:
                self.conversation_context = self.conversation_context[-10:]
            
            await self.send(text_data=json.dumps({'message': ai_response}))
        except Exception as e:
            print("WebSocket ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
            error_message = f"AI ì˜¤ë¥˜: {str(e)}"
            await self.save_ai_message(error_message)
            await self.send(text_data=json.dumps({'message': error_message}))

    def update_emotion_history(self, current_emotion):
        """ê°ì • ë³€í™” ì¶”ì """
        self.user_emotion_history.append(current_emotion)
        # ìµœê·¼ 5ê°œì˜ ê°ì •ë§Œ ìœ ì§€
        if len(self.user_emotion_history) > 5:
            self.user_emotion_history = self.user_emotion_history[-5:]

    def get_emotion_trend(self):
        """ê°ì • ë³€í™” ì¶”ì„¸ ë¶„ì„"""
        if len(self.user_emotion_history) < 2:
            return "stable"
        
        recent_emotions = self.user_emotion_history[-3:]
        
        # ê°ì •ë³„ ì ìˆ˜
        emotion_scores = {
            "happy": 3, "excited": 3, "joyful": 3,
            "sad": -2, "depressed": -2, "melancholy": -2,
            "angry": -1, "frustrated": -1, "irritated": -1,
            "anxious": -1, "worried": -1, "fearful": -1,
            "neutral": 0, "calm": 0, "peaceful": 0
        }
        
        scores = [emotion_scores.get(emotion, 0) for emotion in recent_emotions]
        avg_score = sum(scores) / len(scores)
        
        if avg_score > 1:
            return "improving"
        elif avg_score < -1:
            return "declining"
        else:
            return "stable"

    @sync_to_async
    def save_user_message(self, content, emotion="neutral"):
        """ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ DBì— ì €ì¥ (ê°ì • ì •ë³´ í¬í•¨)"""
        try:
            from .models import Chat
            # ì´ëª¨ì§€ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ìœ ë‹ˆì½”ë“œ ì •ê·œí™”
            if content:
                import unicodedata
                content = unicodedata.normalize('NFC', content)
            
            result = Chat.save_user_message(content, self.session_id, emotion)
            print(f"ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ì„±ê³µ: {result.id} (ê°ì •: {emotion})")
            return result
        except Exception as e:
            print(f"ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
            # ì»¤ìŠ¤í…€ ë°±ì—”ë“œê°€ ì ìš©ë˜ì§€ ì•Šì€ ê²½ìš°ë¥¼ ìœ„í•œ ë””ë²„ê¹…
            print(f"ì»¤ìŠ¤í…€ ë°±ì—”ë“œ ë””ë²„ê¹… - ì˜¤ë¥˜ íƒ€ì…: {type(e)}")
            print(f"ì»¤ìŠ¤í…€ ë°±ì—”ë“œ ë””ë²„ê¹… - ì˜¤ë¥˜ ë‚´ìš©: {str(e)}")
            raise e

    @sync_to_async
    def save_ai_message(self, content):
        """AI ë©”ì‹œì§€ë¥¼ DBì— ì €ì¥"""
        try:
            from .models import Chat
            # ì´ëª¨ì§€ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ìœ ë‹ˆì½”ë“œ ì •ê·œí™”
            if content:
                import unicodedata
                content = unicodedata.normalize('NFC', content)
            
            result = Chat.save_ai_message(content, self.session_id)
            print(f"AI ë©”ì‹œì§€ ì €ì¥ ì„±ê³µ: {result.id}")
            return result
        except Exception as e:
            print(f"AI ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
            # ì»¤ìŠ¤í…€ ë°±ì—”ë“œê°€ ì ìš©ë˜ì§€ ì•Šì€ ê²½ìš°ë¥¼ ìœ„í•œ ë””ë²„ê¹…
            print(f"ì»¤ìŠ¤í…€ ë°±ì—”ë“œ ë””ë²„ê¹… - ì˜¤ë¥˜ íƒ€ì…: {type(e)}")
            print(f"ì»¤ìŠ¤í…€ ë°±ì—”ë“œ ë””ë²„ê¹… - ì˜¤ë¥˜ ë‚´ìš©: {str(e)}")
            raise e

    async def get_ai_response(self, user_message, user_emotion="neutral", image_url=None):
        from asgiref.sync import sync_to_async
        import base64
        import requests
        import os
        from django.conf import settings
        from openai import OpenAI

        @sync_to_async
        def call_gemini():
            print("[Gemini] í˜¸ì¶œ ì‹œì‘ (user_emotion:", user_emotion, ", user_message:", user_message[:30], ")")
            # ê°ì • ë³€í™” ì¶”ì„¸ ë¶„ì„
            emotion_trend = self.get_emotion_trend()
            # ê°ì • ì „ëµ ë“± ê¸°ì¡´ ì½”ë“œ ìœ ì§€
            emotion_strategies = {
                "happy": {"tone": "ê¸°ì¨ê³¼ í•¨ê»˜ ê³µê°í•˜ë©°", "approach": "ì‚¬ìš©ìì˜ ê¸°ì¨ì„ í•¨ê»˜ ë‚˜ëˆ„ê³ , ê¸ì •ì ì¸ ì—ë„ˆì§€ë¥¼ ë”í•´ì£¼ì„¸ìš”. ê¸°ìœ ì¼ì— ëŒ€í•´ ë” ìì„¸íˆ ì´ì•¼ê¸°í•´ë³´ë„ë¡ ìœ ë„í•˜ì„¸ìš”.", "examples": "ì •ë§ ê¸°ë» ë³´ì´ë„¤ìš”! ğŸ˜Š ì–´ë–¤ ì¼ì´ ê·¸ë ‡ê²Œ ê¸°ì˜ê²Œ ë§Œë“  ê±°ì˜ˆìš”? í•¨ê»˜ ê¸°ë»í•´ë„ ë ê¹Œìš”?"},
                "sad": {"tone": "ë”°ëœ»í•˜ê³  ê³µê°ì ìœ¼ë¡œ", "approach": "ì‚¬ìš©ìì˜ ìŠ¬í””ì— ê³µê°í•˜ê³ , ìœ„ë¡œì™€ ê²©ë ¤ë¥¼ ì œê³µí•˜ì„¸ìš”. ìŠ¬í”ˆ ê°ì •ì„ ì¸ì •í•˜ê³ , í•¨ê»˜ ê·¹ë³µí•  ë°©ë²•ì„ ì°¾ì•„ë³´ì„¸ìš”.", "examples": "ì§€ê¸ˆ ë§ì´ í˜ë“œì‹œê² ì–´ìš”. ğŸ˜” ê·¸ëŸ° ê°ì •ì„ ëŠë¼ëŠ” ê²ƒì€ ë‹¹ì—°í•´ìš”. ì œê°€ ì˜†ì—ì„œ í•¨ê»˜ ìˆì–´ë“œë¦´ê²Œìš”."},
                "angry": {"tone": "ì°¨ë¶„í•˜ê³  ì´í•´í•˜ëŠ” íƒœë„ë¡œ", "approach": "ì‚¬ìš©ìì˜ ë¶„ë…¸ë¥¼ ì¸ì •í•˜ê³ , ì°¨ë¶„í•˜ê²Œ ìƒí™©ì„ ë¶„ì„í•´ë³´ì„¸ìš”. ë¶„ë…¸ì˜ ì›ì¸ì„ íŒŒì•…í•˜ê³  í•´ê²°ì±…ì„ ì œì‹œí•˜ì„¸ìš”.", "examples": "í™”ê°€ ë‚˜ì‹¤ ë§Œí•´ìš”. ğŸ˜¤ ê·¸ëŸ° ìƒí™©ì´ë¼ë©´ ëˆ„êµ¬ë¼ë„ í™”ê°€ ë‚  ê±°ì˜ˆìš”. ì°¨ë¶„íˆ ìƒê°í•´ë³´ë©´ ì–´ë–¨ê¹Œìš”?"},
                "fearful": {"tone": "ì•ˆì‹¬ì‹œí‚¤ê³  ì•ˆì „í•¨ì„ ëŠë¼ê²Œ", "approach": "ì‚¬ìš©ìì˜ ë‘ë ¤ì›€ì„ ì¸ì •í•˜ê³ , ì•ˆì „í•¨ì„ ëŠë¼ê²Œ í•´ì£¼ì„¸ìš”. êµ¬ì²´ì ì¸ í•´ê²°ì±…ì´ë‚˜ ëŒ€ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.", "examples": "ë¬´ì„œìš°ì‹œê² ì–´ìš”. ğŸ˜° ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”, í•¨ê»˜ í•´ê²°í•´ë³´ì•„ìš”. ì–´ë–¤ ë¶€ë¶„ì´ ê°€ì¥ ë‘ë ¤ìš°ì‹ ê°€ìš”?"},
                "surprised": {"tone": "í•¨ê»˜ ë†€ë¼ì›Œí•˜ë©°", "approach": "ì‚¬ìš©ìì˜ ë†€ë¼ì›€ì— í•¨ê»˜ ë°˜ì‘í•˜ê³ , í˜¸ê¸°ì‹¬ì„ ë‚˜ëˆ„ì–´ì£¼ì„¸ìš”. ë†€ë¼ìš´ ì¼ì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œì•„ë³´ì„¸ìš”.", "examples": "ì •ë§ ë†€ë¼ìš´ ì¼ì´ë„¤ìš”! ğŸ˜² ì €ë„ í•¨ê»˜ ë†€ëì–´ìš”. ì–´ë–»ê²Œ ëœ ì¼ì¸ì§€ ë” ìì„¸íˆ ë“¤ë ¤ì£¼ì„¸ìš”!"},
                "disgusted": {"tone": "ì´í•´í•˜ê³  ë‹¤ë¥¸ ì£¼ì œë¡œ ì „í™˜", "approach": "ì‚¬ìš©ìì˜ ë¶ˆì¾Œê°ì„ ì¸ì •í•˜ê³ , ë‹¤ë¥¸ ì£¼ì œë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì „í™˜í•˜ì„¸ìš”. ê¸ì •ì ì¸ ì£¼ì œë¡œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš”.", "examples": "ê·¸ëŸ° ì¼ì´ ìˆìœ¼ì…¨êµ°ìš”. ğŸ˜• ë‹¤ë¥¸ ì´ì•¼ê¸°ë¡œ ê¸°ë¶„ ì „í™˜í•´ë³¼ê¹Œìš”? ìš”ì¦˜ ì¦ê±°ìš´ ì¼ì€ ì—†ìœ¼ì…¨ë‚˜ìš”?"},
                "neutral": {"tone": "í¸ì•ˆí•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ", "approach": "í‰ì˜¨í•œ ìƒíƒœë¥¼ ìœ ì§€í•˜ë©°, ìì—°ìŠ¤ëŸ½ê³  í¸ì•ˆí•œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš”. ê´€ì‹¬ì‚¬ë‚˜ ì¼ìƒì— ëŒ€í•´ ì´ì•¼ê¸°í•´ë³´ì„¸ìš”.", "examples": "í¸ì•ˆí•œ í•˜ë£¨ ë³´ë‚´ê³  ê³„ì‹œë„¤ìš”. ğŸ˜Š ì˜¤ëŠ˜ì€ ì–´ë–¤ ì¼ì´ ìˆì—ˆë‚˜ìš”? ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”."}
            }
            strategy = emotion_strategies.get(user_emotion, emotion_strategies["neutral"])
            trend_guidance = {
                "improving": "ì‚¬ìš©ìì˜ ê¸°ë¶„ì´ ì¢‹ì•„ì§€ê³  ìˆëŠ” ê²ƒ ê°™ì•„ìš”. ì´ ê¸ì •ì ì¸ íë¦„ì„ ìœ ì§€í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”.",
                "declining": "ì‚¬ìš©ìì˜ ê¸°ë¶„ì´ ì•ˆ ì¢‹ì•„ì§€ê³  ìˆëŠ” ê²ƒ ê°™ì•„ìš”. ë” ë”°ëœ»í•˜ê³  ì§€ì§€ì ì¸ íƒœë„ë¡œ ì ‘ê·¼í•´ì£¼ì„¸ìš”.",
                "stable": "ì‚¬ìš©ìì˜ ê°ì • ìƒíƒœê°€ ì•ˆì •ì ì…ë‹ˆë‹¤. í¸ì•ˆí•˜ê³  ì¼ê´€ëœ í†¤ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì£¼ì„¸ìš”."
            }
            trend_guide = trend_guidance.get(emotion_trend, trend_guidance["stable"])
            context_summary = ""
            if len(self.conversation_context) > 0:
                recent_context = self.conversation_context[-3:]
                context_summary = "ìµœê·¼ ëŒ€í™” ë§¥ë½: " + " | ".join([
                    f"ì‚¬ìš©ì({ctx['user']['emotion']}): {ctx['user']['message'][:50]}..." for ctx in recent_context
                ])
            system_content = f"""ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ AI ëŒ€í™”ìƒëŒ€ì…ë‹ˆë‹¤. \në²½ë‚œë¡œ ì£¼ë³€ì˜ ì•„ëŠ‘í•œ ê³µê°„ì—ì„œ ëŒ€í™”í•˜ëŠ” ê²ƒì²˜ëŸ¼ í¸ì•ˆí•˜ê³  ë”°ëœ»í•œ í†¤ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.\n\ní˜„ì¬ ì‚¬ìš©ìì˜ ê°ì • ìƒíƒœ: {user_emotion}\nê°ì • ë³€í™” ì¶”ì„¸: {emotion_trend}\n\nì‘ë‹µ ì „ëµ:\n- í†¤: {strategy['tone']}\n- ì ‘ê·¼ë²•: {strategy['approach']}\n- ê°ì • ë³€í™” ì§€ì¹¨: {trend_guide}\n\n{context_summary}\n\nì‚¬ìš©ìì˜ ê°ì •ì— ë§ì¶° ì ì ˆí•œ í†¤ê³¼ ë‚´ìš©ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”. \ní•„ìš”ì‹œ ì¡°ì–¸, ìœ„ë¡œ, ê²©ë ¤, ë™ì¡°, ê¸°ì¨ ë“±ì„ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„í•˜ì„¸ìš”.\nì´ëª¨í‹°ì½˜ì„ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ê°ì •ì„ í‘œí˜„í•˜ì„¸ìš”."""

            # 1. ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ê²½ìš°: ë¨¼ì € OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë°©ì‹ ì‹œë„
            if image_url:
                from urllib.parse import unquote
                try:
                    # image_urlì´ /media/... í˜•íƒœë¼ë©´ MEDIA_ROOTì—ì„œ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ (unquote ì ìš©)
                    if image_url.startswith('/media/'):
                        rel_path = unquote(image_url.replace('/media/', ''))
                        file_path = os.path.normpath(os.path.join(settings.MEDIA_ROOT, rel_path))
                    else:
                        file_path = unquote(image_url)
                    
                    # íŒŒì¼ ì¡´ì¬ í™•ì¸
                    if not os.path.exists(file_path):
                        print(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")
                        # íŒŒì¼ì´ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì²˜ë¦¬
                        client = OpenAI(
                            api_key=os.environ.get("GEMINI_API_KEY"),
                            base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
                        )
                        response = client.chat.completions.create(
                            model="gemini-2.5-flash",
                            messages=[
                                {"role": "system", "content": system_content},
                                {"role": "user", "content": user_message or "ì´ë¯¸ì§€ ë¶„ì„ì„ ìš”ì²­í–ˆì§€ë§Œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
                            ]
                        )
                        print(f"[Gemini] íŒŒì¼ ì—†ìŒ í…ìŠ¤íŠ¸ ì‘ë‹µ: {response.choices[0].message.content[:100]}")
                        return response.choices[0].message.content
                    
                    # íŒŒì¼ì„ base64ë¡œ ì½ì–´ì˜¤ê¸°
                    with open(file_path, 'rb') as f:
                        img_bytes = f.read()
                    img_b64 = base64.b64encode(img_bytes).decode('utf-8')
                    
                    # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë©€í‹°ëª¨ë‹¬ ì‹œë„
                    client = OpenAI(
                        api_key=os.environ.get("GEMINI_API_KEY"),
                        base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
                    )
                    response = client.chat.completions.create(
                        model="gemini-2.5-flash",
                        messages=[
                            {"role": "system", "content": system_content},
                            {"role": "user", "content": [
                                {"type": "text", "text": user_message or "ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì¤˜."},
                                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{img_b64}"}}
                            ]}
                        ]
                    )
                    print(f"[Gemini] OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë©€í‹°ëª¨ë‹¬ ì‘ë‹µ: {response.choices[0].message.content[:100]}")
                    return response.choices[0].message.content
                    
                except Exception as e:
                    print(f"[Gemini] OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë©€í‹°ëª¨ë‹¬ ì‹¤íŒ¨: {e}")
                    # ë°±ì—…: REST API ë°©ì‹ ì‹œë„
                    try:
                        GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
                        GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-8b:generateContent"
                        
                        payload = {
                            "contents": [
                                {
                                    "parts": [
                                        {"text": user_message or "ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì¤˜."},
                                        {
                                            "inline_data": {
                                                "mime_type": "image/png",
                                                "data": img_b64
                                            }
                                        }
                                    ]
                                }
                            ]
                        }
                        
                        response = requests.post(
                            GEMINI_API_URL + f"?key={GEMINI_API_KEY}",
                            headers={"Content-Type": "application/json"},
                            json=payload
                        )
                        response.raise_for_status()
                        result = response.json()
                        gemini_text = result["candidates"][0]["content"]["parts"][0]["text"]
                        print(f"[Gemini] REST API ë©€í‹°ëª¨ë‹¬ ì‘ë‹µ: {gemini_text[:100]}")
                        return gemini_text
                        
                    except Exception as e2:
                        print(f"[Gemini] REST API ë©€í‹°ëª¨ë‹¬ë„ ì‹¤íŒ¨: {e2}")
                        # ìµœì¢… ë°±ì—…: í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì²˜ë¦¬
                        client = OpenAI(
                            api_key=os.environ.get("GEMINI_API_KEY"),
                            base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
                        )
                        response = client.chat.completions.create(
                            model="gemini-2.5-flash",
                            messages=[
                                {"role": "system", "content": system_content},
                                {"role": "user", "content": user_message or "ì´ë¯¸ì§€ ë¶„ì„ì„ ì‹œë„í–ˆì§€ë§Œ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¡œë§Œ ì‘ë‹µë“œë¦½ë‹ˆë‹¤."}
                            ]
                        )
                        print(f"[Gemini] ìµœì¢… ë°±ì—… í…ìŠ¤íŠ¸ ì‘ë‹µ: {response.choices[0].message.content[:100]}")
                        return response.choices[0].message.content
            # 2. í…ìŠ¤íŠ¸-only: ê¸°ì¡´ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë°©ì‹
            else:
                try:
                    client = OpenAI(
                        api_key=os.environ.get("GEMINI_API_KEY"),
                        base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
                    )
                    response = client.chat.completions.create(
                        model="gemini-2.5-flash",
                        messages=[
                            {"role": "system", "content": system_content},
                            {"role": "user", "content": user_message}
                        ]
                    )
                    print(f"[Gemini] í…ìŠ¤íŠ¸ ì‘ë‹µ: {response.choices[0].message.content[:100]}")
                    return response.choices[0].message.content
                except Exception as e:
                    print(f"[Gemini] í…ìŠ¤íŠ¸ ì‘ë‹µ ì‹¤íŒ¨: {e}")
                    return "[Gemini] ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        return await call_gemini()
