import { getApiBase, csrfFetch, getCookie } from '../app.js';

class AIService {
    constructor() {
        this.settings = null;
        this.isInitialized = false;
    }

    // AI ì„¤ì • ì´ˆê¸°í™”
    initialize(settings) {
        this.settings = settings;
        this.isInitialized = true;
        // console.log('ğŸ¤– AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™”ë¨:', settings);
        // console.log('ğŸ”§ í˜„ì¬ AI ì œê³µì:', settings.aiProvider);
        // console.log('ğŸ”§ Lily API URL:', settings.lilyApiUrl);
        // console.log('ğŸ”§ Lily ëª¨ë¸:', settings.lilyModel);
    }

    // AI ì‘ë‹µ ìƒì„±
    async generateResponse(message, context = '', options = {}) {
        if (!this.isInitialized || !this.settings?.aiEnabled) {
            throw new Error('AI ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
        }

        console.log('ğŸš€ AI ì‘ë‹µ ìƒì„± ì‹œì‘');
        console.log('ğŸ“ ë©”ì‹œì§€:', message);
        console.log('ğŸ”§ AI ì œê³µì:', this.settings.aiProvider);
        console.log('ğŸ”§ í˜„ì¬ ì„¤ì •:', this.settings);

        try {
            switch (this.settings.aiProvider) {
                case 'lily':
                    console.log('ğŸŒ¿ Lily LLM ì‚¬ìš©');
                    return await this.generateLilyResponse(message, context, options);
                case 'chatgpt':
                    console.log('ğŸ’¬ ChatGPT ì‚¬ìš©');
                    return await this.generateChatGPTResponse(message, context);
                case 'gemini':
                    console.log('ğŸŒŸ Gemini ì‚¬ìš©');
                    return await this.generateGeminiResponse(message, context);
                default:
                    console.error('âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” AI ì œê³µì:', this.settings.aiProvider);
                    throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” AI ì œê³µì: ${this.settings.aiProvider}`);
            }
        } catch (error) {
            console.error('âŒ AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error);
            throw error;
        }
    }

    // Lily API ì‘ë‹µ ìƒì„±
    async generateLilyResponse(message, context = '', options = {}) {
        console.log('ğŸŒ¿ Lily API í˜¸ì¶œ ì‹œì‘');
        console.log('ğŸ”— API URL:', `${this.settings.lilyApiUrl}/api/v2/generate`);
        console.log('ğŸ”§ ëª¨ë¸:', this.settings.lilyModel);

        const url = `${this.settings.lilyApiUrl}/api/v2/generate`;

        const formData = new FormData();
        formData.append('prompt', message);
        formData.append('model_id', this.settings.lilyModel);
        formData.append('max_length', this.settings.maxTokens);
        formData.append('temperature', this.settings.temperature);
        // formData.append('top_p', 0.9);
        // formData.append('do_sample', true);
        // formData.append('use_rag_text', true);
        // formData.append('image_short_side', 128);

        // ì˜µì…˜ ì „ë‹¬: use_rag_images / use_rag_text / image_short_side
        try {
            const { useRagImages, useRagText, imageShortSide } = options || {};
            if (typeof useRagImages === 'boolean') {
                formData.append('use_rag_images', useRagImages ? 'true' : 'false');
            }
            if (typeof useRagText === 'boolean') {
                formData.append('use_rag_text', useRagText ? 'true' : 'false');
            }
            if (typeof imageShortSide === 'number') {
                formData.append('image_short_side', String(imageShortSide));
            }
        } catch (e) {
            console.warn('ì˜µì…˜ ì „ë‹¬ ì¤‘ ê²½ê³ :', e);
        }

        console.log('ğŸ“¤ ìš”ì²­ ë°ì´í„°:', {
            prompt: message,
            model_id: this.settings.lilyModel,
            max_length: this.settings.maxTokens,
            temperature: this.settings.temperature,
            ...(options && typeof options.useRagImages === 'boolean' ? { use_rag_images: options.useRagImages } : {}),
            ...(options && typeof options.useRagText === 'boolean' ? { use_rag_text: options.useRagText } : {}),
            ...(options && typeof options.imageShortSide === 'number' ? { image_short_side: options.imageShortSide } : {})
        });

        const response = await fetch(url, {
            method: 'POST',
            body: formData
        });

        console.log('ğŸ“¥ ì‘ë‹µ ìƒíƒœ:', response.status, response.statusText);

        if (!response.ok) {
            const errorText = await response.text();
            console.error('âŒ Lily API ì˜¤ë¥˜:', errorText);
            throw new Error(`Lily API ì˜¤ë¥˜: ${response.status} ${response.statusText} - ${errorText}`);
        }

        const data = await response.json();
        console.log('âœ… Lily API ì‘ë‹µ ì„±ê³µ:', data);

        return {
            text: data.generated_text,
            model: data.model_name,
            processingTime: data.processing_time
        };
    }

    // ChatGPT API ì‘ë‹µ ìƒì„±
    async generateChatGPTResponse(message, context = '') {
        const url = 'https://api.openai.com/v1/chat/completions';

        const requestBody = {
            model: 'gpt-3.5-turbo',
            messages: [
                {
                    role: 'system',
                    content: 'ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ì£¼ì„¸ìš”.'
                },
                {
                    role: 'user',
                    content: context ? `${context}\n\nì‚¬ìš©ì: ${message}` : message
                }
            ],
            max_tokens: this.settings.maxTokens,
            temperature: this.settings.temperature,
            top_p: 0.9
        };

        const response = await fetch(url, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${this.settings.chatgptApiKey}`
            },
            body: JSON.stringify(requestBody)
        });

        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(`ChatGPT API ì˜¤ë¥˜: ${errorData.error?.message || response.statusText}`);
        }

        const data = await response.json();
        return {
            text: data.choices[0].message.content,
            model: 'gpt-3.5-turbo',
            processingTime: null
        };
    }

    // Gemini API ì‘ë‹µ ìƒì„±
    async generateGeminiResponse(message, context = '') {
        const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${this.settings.geminiApiKey}`;

        const requestBody = {
            contents: [
                {
                    parts: [
                        {
                            text: context ? `${context}\n\nì‚¬ìš©ì: ${message}` : message
                        }
                    ]
                }
            ],
            generationConfig: {
                maxOutputTokens: this.settings.maxTokens,
                temperature: this.settings.temperature,
                topP: 0.9
            }
        };

        const response = await fetch(url, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify(requestBody)
        });

        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(`Gemini API ì˜¤ë¥˜: ${errorData.error?.message || response.statusText}`);
        }

        const data = await response.json();
        return {
            text: data.candidates[0].content.parts[0].text,
            model: 'gemini-pro',
            processingTime: null
        };
    }

    // AI ì‘ë‹µ ì§€ì—° ì²˜ë¦¬
    async generateResponseWithDelay(message, context = '') {
        if (this.settings.responseDelay > 0) {
            console.log(`â³ ì‘ë‹µ ì§€ì—°: ${this.settings.responseDelay}ms`);
            await new Promise(resolve => setTimeout(resolve, this.settings.responseDelay));
        }

        return await this.generateResponse(message, context);
    }

    // AI ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    getSettings() {
        return this.settings;
    }

    // AI í™œì„±í™” ìƒíƒœ í™•ì¸
    isEnabled() {
        return this.isInitialized && this.settings?.aiEnabled;
    }

    // ìë™ ì‘ë‹µ í™œì„±í™” ìƒíƒœ í™•ì¸
    isAutoRespondEnabled() {
        return this.isEnabled() && this.settings?.autoRespond;
    }

    // AI ì œê³µì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    getProviderInfo() {
        if (!this.settings) return null;

        const providers = {
            lily: {
                name: 'Lily LLM',
                description: 'ë¡œì»¬ ì‹¤í–‰ AI ëª¨ë¸',
                color: '#667eea'
            },
            chatgpt: {
                name: 'ChatGPT',
                description: 'OpenAI GPT ëª¨ë¸',
                color: '#10a37f'
            },
            gemini: {
                name: 'Gemini',
                description: 'Google AI ëª¨ë¸',
                color: '#4285f4'
            }
        };

        return providers[this.settings.aiProvider] || null;
    }

    // ì—°ê²° í…ŒìŠ¤íŠ¸
    async testConnection() {
        if (!this.settings) {
            throw new Error('AI ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.');
        }

        try {
            switch (this.settings.aiProvider) {
                case 'lily':
                    console.log('ğŸ”— Lily API ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...');
                    const response = await fetch(`${this.settings.lilyApiUrl}/api/v2/health`);
                    if (!response.ok) {
                        throw new Error(`Lily API ì—°ê²° ì‹¤íŒ¨: ${response.status}`);
                    }
                    const healthData = await response.json();
                    console.log('âœ… Lily API ì—°ê²° ì„±ê³µ:', healthData);
                    return { success: true, message: 'Lily API ì—°ê²° ì„±ê³µ!' };

                case 'chatgpt':
                    const chatgptResponse = await fetch('https://api.openai.com/v1/models', {
                        headers: {
                            'Authorization': `Bearer ${this.settings.chatgptApiKey}`
                        }
                    });
                    if (!chatgptResponse.ok) {
                        throw new Error(`ChatGPT API ì—°ê²° ì‹¤íŒ¨: ${chatgptResponse.status}`);
                    }
                    return { success: true, message: 'ChatGPT API ì—°ê²° ì„±ê³µ!' };

                case 'gemini':
                    const geminiResponse = await fetch(`https://generativelanguage.googleapis.com/v1beta/models?key=${this.settings.geminiApiKey}`);
                    if (!geminiResponse.ok) {
                        throw new Error(`Gemini API ì—°ê²° ì‹¤íŒ¨: ${geminiResponse.status}`);
                    }
                    return { success: true, message: 'Gemini API ì—°ê²° ì„±ê³µ!' };

                default:
                    throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” AI ì œê³µì: ${this.settings.aiProvider}`);
            }
        } catch (error) {
            console.error('âŒ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error);
            return { success: false, message: error.message };
        }
    }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
const aiService = new AIService();

export default aiService; 