import { getApiBase } from '../app';

class AIService {
    constructor() {
        this.settings = null;
        this.isInitialized = false;
    }

    // AI ì„¤ì • ì´ˆê¸°í™”
    initialize(settings) {
        this.settings = settings;
        this.isInitialized = true;
        console.log('ğŸ¤– AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™”ë¨:', settings);
    }

    // AI ì‘ë‹µ ìƒì„±
    async generateResponse(message, context = '') {
        if (!this.isInitialized || !this.settings?.aiEnabled) {
            throw new Error('AI ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
        }

        try {
            switch (this.settings.aiProvider) {
                case 'lily':
                    return await this.generateLilyResponse(message, context);
                case 'chatgpt':
                    return await this.generateChatGPTResponse(message, context);
                case 'gemini':
                    return await this.generateGeminiResponse(message, context);
                default:
                    throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” AI ì œê³µì: ${this.settings.aiProvider}`);
            }
        } catch (error) {
            console.error('AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error);
            throw error;
        }
    }

    // Lily API ì‘ë‹µ ìƒì„±
    async generateLilyResponse(message, context = '') {
        const url = `${this.settings.lilyApiUrl}/generate`;

        const formData = new FormData();
        formData.append('prompt', message);
        formData.append('model_id', this.settings.lilyModel);
        formData.append('max_length', this.settings.maxTokens);
        formData.append('temperature', this.settings.temperature);
        formData.append('top_p', 0.9);
        formData.append('do_sample', true);

        const response = await fetch(url, {
            method: 'POST',
            body: formData
        });

        if (!response.ok) {
            throw new Error(`Lily API ì˜¤ë¥˜: ${response.status} ${response.statusText}`);
        }

        const data = await response.json();
        return {
            text: data.generated_text,
            model: data.model_name,
            processingTime: data.processing_time
        };
    }

    // ChatGPT API ì‘ë‹µ ìƒì„±
    async generateChatGPTResponse(message, context = '') {
        const url = 'https://api.openai.com/v1/chat/completions';

        const requestBody = {
            model: 'gpt-3.5-turbo',
            messages: [
                {
                    role: 'system',
                    content: 'ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ì£¼ì„¸ìš”.'
                },
                {
                    role: 'user',
                    content: context ? `${context}\n\nì‚¬ìš©ì: ${message}` : message
                }
            ],
            max_tokens: this.settings.maxTokens,
            temperature: this.settings.temperature,
            top_p: 0.9
        };

        const response = await fetch(url, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${this.settings.chatgptApiKey}`
            },
            body: JSON.stringify(requestBody)
        });

        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(`ChatGPT API ì˜¤ë¥˜: ${errorData.error?.message || response.statusText}`);
        }

        const data = await response.json();
        return {
            text: data.choices[0].message.content,
            model: 'gpt-3.5-turbo',
            processingTime: null
        };
    }

    // Gemini API ì‘ë‹µ ìƒì„±
    async generateGeminiResponse(message, context = '') {
        const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${this.settings.geminiApiKey}`;

        const requestBody = {
            contents: [
                {
                    parts: [
                        {
                            text: context ? `${context}\n\nì‚¬ìš©ì: ${message}` : message
                        }
                    ]
                }
            ],
            generationConfig: {
                maxOutputTokens: this.settings.maxTokens,
                temperature: this.settings.temperature,
                topP: 0.9
            }
        };

        const response = await fetch(url, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify(requestBody)
        });

        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(`Gemini API ì˜¤ë¥˜: ${errorData.error?.message || response.statusText}`);
        }

        const data = await response.json();
        return {
            text: data.candidates[0].content.parts[0].text,
            model: 'gemini-pro',
            processingTime: null
        };
    }

    // AI ì‘ë‹µ ì§€ì—° ì²˜ë¦¬
    async generateResponseWithDelay(message, context = '') {
        if (this.settings.responseDelay > 0) {
            await new Promise(resolve => setTimeout(resolve, this.settings.responseDelay));
        }

        return await this.generateResponse(message, context);
    }

    // AI ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    getSettings() {
        return this.settings;
    }

    // AI í™œì„±í™” ìƒíƒœ í™•ì¸
    isEnabled() {
        return this.isInitialized && this.settings?.aiEnabled;
    }

    // ìë™ ì‘ë‹µ í™œì„±í™” ìƒíƒœ í™•ì¸
    isAutoRespondEnabled() {
        return this.isEnabled() && this.settings?.autoRespond;
    }

    // AI ì œê³µì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    getProviderInfo() {
        if (!this.settings) return null;

        const providers = {
            lily: {
                name: 'Lily LLM',
                description: 'ë¡œì»¬ ì‹¤í–‰ AI ëª¨ë¸',
                color: '#667eea'
            },
            chatgpt: {
                name: 'ChatGPT',
                description: 'OpenAI GPT ëª¨ë¸',
                color: '#10a37f'
            },
            gemini: {
                name: 'Gemini',
                description: 'Google AI ëª¨ë¸',
                color: '#4285f4'
            }
        };

        return providers[this.settings.aiProvider] || null;
    }

    // ì—°ê²° í…ŒìŠ¤íŠ¸
    async testConnection() {
        if (!this.settings) {
            throw new Error('AI ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.');
        }

        try {
            switch (this.settings.aiProvider) {
                case 'lily':
                    const response = await fetch(`${this.settings.lilyApiUrl}/health`);
                    if (!response.ok) {
                        throw new Error(`Lily API ì—°ê²° ì‹¤íŒ¨: ${response.status}`);
                    }
                    return { success: true, message: 'Lily API ì—°ê²° ì„±ê³µ!' };

                case 'chatgpt':
                    const chatgptResponse = await fetch('https://api.openai.com/v1/models', {
                        headers: {
                            'Authorization': `Bearer ${this.settings.chatgptApiKey}`
                        }
                    });
                    if (!chatgptResponse.ok) {
                        throw new Error(`ChatGPT API ì—°ê²° ì‹¤íŒ¨: ${chatgptResponse.status}`);
                    }
                    return { success: true, message: 'ChatGPT API ì—°ê²° ì„±ê³µ!' };

                case 'gemini':
                    const geminiResponse = await fetch(`https://generativelanguage.googleapis.com/v1beta/models?key=${this.settings.geminiApiKey}`);
                    if (!geminiResponse.ok) {
                        throw new Error(`Gemini API ì—°ê²° ì‹¤íŒ¨: ${geminiResponse.status}`);
                    }
                    return { success: true, message: 'Gemini API ì—°ê²° ì„±ê³µ!' };

                default:
                    throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” AI ì œê³µì: ${this.settings.aiProvider}`);
            }
        } catch (error) {
            return { success: false, message: error.message };
        }
    }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
const aiService = new AIService();

export default aiService; 