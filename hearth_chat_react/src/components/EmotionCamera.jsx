import React, { useRef, useEffect, useState, useCallback } from 'react';
import './EmotionCamera.css';

const EmotionCamera = ({ onEmotionDetected, isActive = true, hideControls = false, isRealTimeMode: externalRealTimeMode = false }) => {
    const videoRef = useRef(null);
    const canvasRef = useRef(null);
    const streamRef = useRef(null);
    const animationRef = useRef(null);
    const [isCameraOn, setIsCameraOn] = useState(false);
    const [currentEmotion, setCurrentEmotion] = useState('neutral');
    const [isAnalyzing, setIsAnalyzing] = useState(false);
    const [error, setError] = useState(null);
    const [emotionHistory, setEmotionHistory] = useState([]);
    const [lastAnalysisTime, setLastAnalysisTime] = useState(0);
    const [internalRealTimeMode, setInternalRealTimeMode] = useState(false); // ë‚´ë¶€ ì‹¤ì‹œê°„ ëª¨ë“œ í† ê¸€

    // ì™¸ë¶€ì—ì„œ ì „ë‹¬ë°›ì€ ëª¨ë“œê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ë‚´ë¶€ ìƒíƒœ ì‚¬ìš©
    const isRealTimeMode = externalRealTimeMode !== false ? externalRealTimeMode : internalRealTimeMode;

    // ì›¹ìº  ì‹œì‘
    const startCamera = useCallback(async () => {
        try {
            setError(null);
            const stream = await navigator.mediaDevices.getUserMedia({
                video: {
                    width: { ideal: 640 },
                    height: { ideal: 480 },
                    facingMode: 'user'
                }
            });

            streamRef.current = stream;
            if (videoRef.current) {
                videoRef.current.srcObject = stream;
                setIsCameraOn(true);
                // ì¹´ë©”ë¼ ì‹œì‘ ì‹œ ì´ˆê¸° ê°ì • ì„¤ì •
                setCurrentEmotion('neutral');
                onEmotionDetected('neutral');
                console.log('ì¹´ë©”ë¼ ì‹œì‘ë¨, ì´ˆê¸° ê°ì • ì„¤ì •: neutral');
            }
        } catch (err) {
            console.error('ì›¹ìº  ì‹œì‘ ì‹¤íŒ¨:', err);
            setError('ì›¹ìº ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
        }
    }, []);

    // ì›¹ìº  ì¤‘ì§€
    const stopCamera = useCallback(() => {
        if (streamRef.current) {
            streamRef.current.getTracks().forEach(track => track.stop());
            streamRef.current = null;
        }
        if (videoRef.current) {
            videoRef.current.srcObject = null;
        }
        setIsCameraOn(false);
        setCurrentEmotion('neutral');
    }, []);

    // ê°ì • ë¶„ì„ í•¨ìˆ˜
    const analyzeEmotion = useCallback(async (imageData) => {
        if (!isActive || isAnalyzing) return;

        setIsAnalyzing(true);
        try {
            // Canvasì—ì„œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
            const canvas = canvasRef.current;
            const ctx = canvas.getContext('2d');

            // ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ìº”ë²„ìŠ¤ì— ê·¸ë¦¬ê¸°
            ctx.drawImage(videoRef.current, 0, 0, canvas.width, canvas.height);

            // ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ base64ë¡œ ë³€í™˜
            const imageBase64 = canvas.toDataURL('image/jpeg', 0.8);

            // ê°ì • ë¶„ì„ API í˜¸ì¶œ (ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜)
            const emotion = await simulateEmotionAnalysis(imageBase64);

            // ê°ì • ì•ˆì •í™”: ê°™ì€ ê°ì •ì´ 3ë²ˆ ì—°ì†ìœ¼ë¡œ ê°ì§€ë˜ë©´ ë³€ê²½
            console.log('ê°ì • ë¶„ì„ ê²°ê³¼:', emotion, 'í˜„ì¬ ê°ì •:', currentEmotion);
            if (emotion && emotion !== currentEmotion) {
                // ì´ì „ ê°ì •ë“¤ê³¼ ë¹„êµí•˜ì—¬ ì•ˆì •ì„± í™•ì¸
                if (shouldUpdateEmotion(emotion)) {
                    setCurrentEmotion(emotion);
                    onEmotionDetected(emotion);
                    console.log('ê°ì • ì—…ë°ì´íŠ¸ë¨:', emotion);
                }
            }
        } catch (err) {
            console.error('ê°ì • ë¶„ì„ ì˜¤ë¥˜:', err);
        } finally {
            setIsAnalyzing(false);
        }
    }, [isActive, isAnalyzing, currentEmotion, onEmotionDetected]);

    // ê°ì • ì—…ë°ì´íŠ¸ í•¨ìˆ˜ (ê°„ì†Œí™”ëœ ë²„ì „)
    const shouldUpdateEmotion = useCallback((newEmotion) => {
        if (isRealTimeMode) {
            // ì‹¤ì‹œê°„ ëª¨ë“œ: 2ë²ˆ ì—°ì† ê°ì§€ ì‹œ ì—…ë°ì´íŠ¸
            const newHistory = [...emotionHistory, newEmotion].slice(-5); // ìµœê·¼ 5ê°œë§Œ ìœ ì§€
            setEmotionHistory(newHistory);

            // ê°™ì€ ê°ì •ì´ 2ë²ˆ ì´ìƒ ì—°ì†ìœ¼ë¡œ ê°ì§€ë˜ë©´ ì—…ë°ì´íŠ¸
            const consecutiveCount = newHistory.filter(emotion => emotion === newEmotion).length;
            const shouldUpdate = consecutiveCount >= 2;

            if (shouldUpdate && newEmotion !== currentEmotion) {
                console.log(`ê°ì • ë³€ê²½ (ì‹¤ì‹œê°„): ${currentEmotion} â†’ ${newEmotion} (${consecutiveCount}ë²ˆ ì—°ì† ê°ì§€)`);
                return true;
            }
            return false;
        } else {
            // ì•ˆì •í™” ëª¨ë“œ: 1ë²ˆ ê°ì§€ ì‹œ ì—…ë°ì´íŠ¸ (3ì´ˆ ê°„ê²©)
            const now = Date.now();
            const timeSinceLastAnalysis = now - lastAnalysisTime;

            // ìµœì†Œ 3ì´ˆ ê°„ê²©ìœ¼ë¡œë§Œ ê°ì • ì—…ë°ì´íŠ¸
            if (timeSinceLastAnalysis < 3000) {
                return false;
            }

            // ê°ì • íˆìŠ¤í† ë¦¬ì— ìƒˆ ê°ì • ì¶”ê°€
            const newHistory = [...emotionHistory, newEmotion].slice(-3); // ìµœê·¼ 3ê°œë§Œ ìœ ì§€
            setEmotionHistory(newHistory);

            // ê°™ì€ ê°ì •ì´ 2ë²ˆ ì´ìƒ ì—°ì†ìœ¼ë¡œ ê°ì§€ë˜ë©´ ì—…ë°ì´íŠ¸
            const consecutiveCount = newHistory.filter(emotion => emotion === newEmotion).length;
            const shouldUpdate = consecutiveCount >= 2;

            if (shouldUpdate) {
                setLastAnalysisTime(now);
                console.log(`ê°ì • ì•ˆì •í™”: ${newEmotion} (${consecutiveCount}ë²ˆ ì—°ì† ê°ì§€)`);
            }

            return shouldUpdate;
        }
    }, [isRealTimeMode, currentEmotion, emotionHistory, lastAnalysisTime]);

    // ê°ì • ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” AI API ì‚¬ìš©)
    const simulateEmotionAnalysis = async (imageData) => {
        // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì—¬ê¸°ì— ê°ì • ë¶„ì„ APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤
        // ì˜ˆ: Google Cloud Vision API, Azure Face API, ë˜ëŠ” ë¡œì»¬ AI ëª¨ë¸

        // ì„ì‹œë¡œ ëœë¤ ê°ì • ë°˜í™˜ (í…ŒìŠ¤íŠ¸ìš©) - ë” ì•ˆì •ì ì¸ ê°ì • ìƒì„±
        const emotions = ['happy', 'sad', 'neutral', 'surprised', 'angry', 'fearful', 'disgusted'];

        // ê°ì • ë³€í™” í™•ë¥  (ëª¨ë“œì— ë”°ë¼ ë‹¤ë¦„)
        if (isRealTimeMode) {
            // ì‹¤ì‹œê°„ ëª¨ë“œ: 50% í™•ë¥ ë¡œ ìœ ì§€, 50% í™•ë¥ ë¡œ ë³€ê²½
            if (currentEmotion && Math.random() < 0.5) {
                return currentEmotion;
            }
        } else {
            // ì•ˆì •í™” ëª¨ë“œ: 60% í™•ë¥ ë¡œ ìœ ì§€, 40% í™•ë¥ ë¡œ ë³€ê²½
            if (currentEmotion && Math.random() < 0.6) {
                return currentEmotion;
            }
        }

        const randomEmotion = emotions[Math.floor(Math.random() * emotions.length)];

        // ì‹¤ì œ êµ¬í˜„ì„ ìœ„í•œ ì£¼ì„
        /*
        try {
            const response = await fetch('/api/analyze-emotion', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ image: imageData })
            });
            
            const result = await response.json();
            return result.emotion;
        } catch (error) {
            console.error('ê°ì • ë¶„ì„ API ì˜¤ë¥˜:', error);
            return 'neutral';
        }
        */

        return randomEmotion;
    };

    // í”„ë ˆì„ ë¶„ì„ ë£¨í”„ (ëª¨ë“œì— ë”°ë¼ ë‹¤ë¦„)
    const analyzeFrame = useCallback(() => {
        if (isCameraOn && isActive && videoRef.current && videoRef.current.readyState === 4) {
            if (isRealTimeMode) {
                // ì‹¤ì‹œê°„ ëª¨ë“œ: 1ì´ˆë§ˆë‹¤ ë¶„ì„
                const now = Date.now();
                if (now - lastAnalysisTime >= 1000) {
                    analyzeEmotion();
                    setLastAnalysisTime(now);
                }
            } else {
                // ì•ˆì •í™” ëª¨ë“œ: 3ì´ˆë§ˆë‹¤ ë¶„ì„
                const now = Date.now();
                if (now - lastAnalysisTime >= 3000) {
                    analyzeEmotion();
                }
            }
        }
        animationRef.current = requestAnimationFrame(analyzeFrame);
    }, [isCameraOn, isActive, analyzeEmotion, isRealTimeMode, lastAnalysisTime]);

    // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸/ì–¸ë§ˆìš´íŠ¸ ì²˜ë¦¬
    useEffect(() => {
        if (isActive) {
            startCamera();
        } else {
            stopCamera();
        }

        return () => {
            stopCamera();
            if (animationRef.current) {
                cancelAnimationFrame(animationRef.current);
            }
        };
    }, [isActive, startCamera, stopCamera]);

    // í”„ë ˆì„ ë¶„ì„ ì‹œì‘/ì¤‘ì§€
    useEffect(() => {
        if (isCameraOn && isActive) {
            analyzeFrame();
        } else {
            if (animationRef.current) {
                cancelAnimationFrame(animationRef.current);
            }
        }

        return () => {
            if (animationRef.current) {
                cancelAnimationFrame(animationRef.current);
            }
        };
    }, [isCameraOn, isActive, analyzeFrame]);

    // ê°ì • ìƒíƒœì— ë”°ë¥¸ CSS í´ë˜ìŠ¤
    const getEmotionClass = (emotion) => {
        if (!emotion) return '';
        return `emotion-${emotion}`;
    };

    return (
        <div className={`emotion-camera ${getEmotionClass(currentEmotion)}`}>
            {/* ì¹´ë©”ë¼ ì œì–´ ë²„íŠ¼ (ìœ„ìª½ ë°°ì¹˜) - hideControlsê°€ falseì¼ ë•Œë§Œ í‘œì‹œ */}
            {!hideControls && (
                <div className="camera-controls-top">
                    <button
                        onClick={isCameraOn ? stopCamera : startCamera}
                        className={`camera-toggle ${isCameraOn ? 'active' : ''}`}
                    >
                        {isCameraOn ? 'ğŸ“· ì¹´ë©”ë¼ ë„ê¸°' : 'ğŸ“· ì¹´ë©”ë¼ ì¼œê¸°'}
                    </button>

                    {/* ëª¨ë“œ í† ê¸€ ë²„íŠ¼ */}
                    <button
                        onClick={() => setInternalRealTimeMode(!internalRealTimeMode)}
                        className={`mode-toggle ${isRealTimeMode ? 'realtime' : 'stable'}`}
                        disabled={!isCameraOn}
                    >
                        {isRealTimeMode ? 'âš¡ ì‹¤ì‹œê°„ ëª¨ë“œ' : 'ğŸ›¡ï¸ ì•ˆì •í™” ëª¨ë“œ'}
                    </button>
                </div>
            )}

            {/* ê°ì • ìƒíƒœ í‘œì‹œ - ì¹´ë©”ë¼ ìœ„ìª½ */}
            <div className="emotion-indicator-top" style={{ display: 'flex !important', visibility: 'visible !important' }}>
                <span className="emotion-label-small">
                    {currentEmotion === 'happy' && 'ğŸ˜Š'}
                    {currentEmotion === 'sad' && 'ğŸ˜¢'}
                    {currentEmotion === 'neutral' && 'ğŸ˜'}
                    {currentEmotion === 'surprised' && 'ğŸ˜²'}
                    {currentEmotion === 'angry' && 'ğŸ˜ '}
                    {currentEmotion === 'fearful' && 'ğŸ˜¨'}
                    {currentEmotion === 'disgusted' && 'ğŸ¤¢'}
                    {!currentEmotion && 'ğŸ˜'}
                </span>
                <span className="emotion-text-small">
                    {currentEmotion === 'happy' && 'ê¸°ì¨'}
                    {currentEmotion === 'sad' && 'ìŠ¬í””'}
                    {currentEmotion === 'neutral' && 'ë¬´í‘œì •'}
                    {currentEmotion === 'surprised' && 'ë†€ëŒ'}
                    {currentEmotion === 'angry' && 'ë¶„ë…¸'}
                    {currentEmotion === 'fearful' && 'ë‘ë ¤ì›€'}
                    {currentEmotion === 'disgusted' && 'í˜ì˜¤'}
                    {!currentEmotion && 'ë¶„ì„ ì¤‘...'}
                </span>
                <span className="emotion-stability-small">
                    {isRealTimeMode
                        ? `ğŸ”„ ì‹¤ì‹œê°„ (${emotionHistory.filter(e => e === currentEmotion).length}/2)`
                        : `ğŸ”’ ì•ˆì • (${emotionHistory.filter(e => e === currentEmotion).length}/2)`
                    }
                </span>
            </div>

            <div className="camera-container">
                <video
                    ref={videoRef}
                    autoPlay
                    playsInline
                    muted
                    className="camera-video"
                />
                <canvas
                    ref={canvasRef}
                    width="640"
                    height="480"
                    style={{ display: 'none' }}
                />

                {/* ë¶„ì„ ì¤‘ í‘œì‹œ */}
                {isAnalyzing && (
                    <div className="analyzing-indicator">
                        <div className="analyzing-spinner"></div>
                        <span>ê°ì • ë¶„ì„ ì¤‘...</span>
                    </div>
                )}

                {/* ì˜¤ë¥˜ ë©”ì‹œì§€ */}
                {error && (
                    <div className="error-message">
                        <span>{error}</span>
                        <button onClick={startCamera} className="retry-button">
                            ë‹¤ì‹œ ì‹œë„
                        </button>
                    </div>
                )}
            </div>
        </div>
    );
};

export default EmotionCamera; 