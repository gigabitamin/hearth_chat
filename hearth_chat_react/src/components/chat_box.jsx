import React, { useState, useEffect, useRef, useMemo } from 'react';
import RealisticAvatar3D from './RealisticAvatar3D';
import EmotionCamera from './EmotionCamera';
import VoiceRecognition from './VoiceRecognition';
import ttsService from '../services/ttsService';
import readyPlayerMeService from '../services/readyPlayerMe';
import faceTrackingService from '../services/faceTrackingService';
import './chat_box.css';
import axios from 'axios';

// ëª¨ë‹¬ ì»´í¬ë„ŒíŠ¸ ì¶”ê°€
const Modal = ({ open, onClose, children }) => {
  if (!open) return null;
  return (
    <div className="voice-modal-overlay" onClick={onClose}>
      <div className="voice-modal-content" onClick={e => e.stopPropagation()}>
        <button className="voice-modal-close" onClick={onClose}>ë‹«ê¸°</button>
        {children}
      </div>
    </div>
  );
};

const ChatBox = () => {
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState('');
  const [userAvatar, setUserAvatar] = useState(null);
  const [aiAvatar, setAiAvatar] = useState(null);
  const [isUserTalking, setIsUserTalking] = useState(false);
  const [isAiTalking, setIsAiTalking] = useState(false);
  const [userEmotion, setUserEmotion] = useState('neutral');
  const [aiEmotion, setAiEmotion] = useState('neutral');
  const [cameraEmotion, setCameraEmotion] = useState('neutral');
  const [isCameraActive, setIsCameraActive] = useState(false);
  const [isRealTimeMode, setIsRealTimeMode] = useState(false);

  // TTS ê´€ë ¨ ìƒíƒœ
  const [isTTSEnabled, setIsTTSEnabled] = useState(true);
  const [ttsVoice, setTtsVoice] = useState(null);
  const [ttsRate, setTtsRate] = useState(1.5);
  const [ttsPitch, setTtsPitch] = useState(1.5);
  const [voiceList, setVoiceList] = useState([]);

  const ws = useRef(null);
  const chatScrollRef = useRef(null);
  const [displayedAiText, setDisplayedAiText] = useState('');
  const [mouthTrigger, setMouthTrigger] = useState(0);
  const [currentAiMessage, setCurrentAiMessage] = useState('');
  const [emotionDisplay, setEmotionDisplay] = useState({ user: 'neutral', ai: 'neutral' });
  const [emotionCaptureStatus, setEmotionCaptureStatus] = useState({ user: false, ai: false });
  const [isVoiceRecognitionEnabled, setIsVoiceRecognitionEnabled] = useState(false);
  const [voiceInterimText, setVoiceInterimText] = useState('');
  const [autoSend, setAutoSend] = useState(true); // ìë™ì „ì†¡ ëª¨ë“œ (ê¸°ë³¸ê°’: true)
  const [isContinuousRecognition, setIsContinuousRecognition] = useState(false); // ì—°ì† ìŒì„±ì¸ì‹ ëª¨ë“œ
  const [accumulatedVoiceText, setAccumulatedVoiceText] = useState(''); // ëˆ„ì ëœ ìŒì„±ì¸ì‹ í…ìŠ¤íŠ¸
  const [silenceTimer, setSilenceTimer] = useState(null); // ë¬µìŒ íƒ€ì´ë¨¸
  const [blockInterim, setBlockInterim] = useState(false); // ìë™ì „ì†¡ ì§í›„ interim ë°˜ì˜ ë°©ì§€

  const voiceRecognitionRef = useRef(null);
  const [isVoiceMenuOpen, setIsVoiceMenuOpen] = useState(false);
  const [permissionStatus, setPermissionStatus] = useState('unknown'); // 'unknown', 'granted', 'denied'

  // íŠ¸ë˜í‚¹ ê´€ë ¨ ìƒíƒœ
  const [isTrackingEnabled, setIsTrackingEnabled] = useState(false);
  const [trackingStatus, setTrackingStatus] = useState('stopped'); // 'stopped', 'starting', 'running', 'error'
  const [faceDetected, setFaceDetected] = useState(false);

  // MediaPipe ì¤€ë¹„ ìƒíƒœ
  const [isTrackingReady, setIsTrackingReady] = useState(false);
  const [isTrackingLoading, setIsTrackingLoading] = useState(true);

  // MediaPipe ì¤€ë¹„ ìƒíƒœ ê°ì‹œ
  useEffect(() => {
    // MediaPipe ì´ˆê¸°í™” ê°•ì œ ì‹œì‘
    if (!faceTrackingService.isReady && !faceTrackingService.isInitializing) {
      console.log('MediaPipe ì´ˆê¸°í™” ê°•ì œ ì‹œì‘...');
      faceTrackingService.initializeMediaPipe();
    }

    // ì£¼ê¸°ì  ì²´í¬ (ìƒíƒœ í‘œì‹œìš©)
    const interval = setInterval(() => {
      setIsTrackingReady(faceTrackingService.isReady);
      setIsTrackingLoading(faceTrackingService.isInitializing);
    }, 2000);

    return () => clearInterval(interval);
  }, []);

  // ëª¨ë°”ì¼ ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤ì œ ë³´ì´ëŠ” ì˜ì—­ì˜ ë†’ì´ë¡œ --real-vh CSS ë³€ìˆ˜ ì„¤ì •
  useEffect(() => {
    function setRealVh() {
      const vh = window.visualViewport
        ? window.visualViewport.height * 0.01
        : window.innerHeight * 0.01;
      document.documentElement.style.setProperty('--real-vh', `${vh}px`);
    }
    window.addEventListener('resize', setRealVh);
    window.addEventListener('orientationchange', setRealVh);
    if (window.visualViewport) {
      window.visualViewport.addEventListener('resize', setRealVh);
      window.visualViewport.addEventListener('scroll', setRealVh);
    }
    setRealVh();
    return () => {
      window.removeEventListener('resize', setRealVh);
      window.removeEventListener('orientationchange', setRealVh);
      if (window.visualViewport) {
        window.visualViewport.removeEventListener('resize', setRealVh);
        window.visualViewport.removeEventListener('scroll', setRealVh);
      }
    };
  }, []);

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ì‹¤í–‰
  useEffect(() => {
    console.log('ChatBox ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ë¨');

    // WebSocket ì—°ê²°
    connectWebSocket();

    // TTS ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    initializeTTSService();

    // ì•„ë°”íƒ€ ì´ˆê¸°í™”
    initializeAvatars();

    // ë§ˆì´í¬ ê¶Œí•œ ìƒíƒœ í™•ì¸
    const checkPermissionStatus = async () => {
      if (navigator.permissions && navigator.permissions.query) {
        try {
          const permission = await navigator.permissions.query({ name: 'microphone' });
          setPermissionStatus(permission.state);
        } catch (error) {
          console.log('ê¶Œí•œ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨:', error);
        }
      }
    };

    checkPermissionStatus();

    // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
    return () => {
      if (ws.current) {
        ws.current.close();
      }
      ttsService.stop();

      // íŠ¸ë˜í‚¹ ì •ë¦¬
      if (isTrackingEnabled) {
        faceTrackingService.stopCamera();
      }
    };
  }, []);

  // ê°ì • í¬ì°© ìƒíƒœ ìë™ ë¦¬ì…‹ (3ì´ˆ í›„)
  useEffect(() => {
    const resetUserEmotionCapture = setTimeout(() => {
      setEmotionCaptureStatus(prev => ({ ...prev, user: false }));
    }, 3000);

    return () => clearTimeout(resetUserEmotionCapture);
  }, [emotionCaptureStatus.user]);

  useEffect(() => {
    const resetAiEmotionCapture = setTimeout(() => {
      setEmotionCaptureStatus(prev => ({ ...prev, ai: false }));
    }, 3000);

    return () => clearTimeout(resetAiEmotionCapture);
  }, [emotionCaptureStatus.ai]);

  // ìƒˆë¡œìš´ ë©”ì‹œì§€ê°€ ì¶”ê°€ë  ë•Œë§ˆë‹¤ ìë™ìœ¼ë¡œ ìŠ¤í¬ë¡¤ì„ ë§¨ ì•„ë˜ë¡œ ì´ë™
  useEffect(() => {
    setTimeout(() => {
      if (chatScrollRef.current) {
        chatScrollRef.current.scrollTop = chatScrollRef.current.scrollHeight;
      }
    }, 0);
  }, [messages, displayedAiText]);

  // TTS ê¸°ë°˜ ë¦½ì‹±í¬ë¥¼ ìœ„í•œ ìƒíƒœ
  const [ttsSpeaking, setTtsSpeaking] = useState(false);
  const [lipSyncInterval, setLipSyncInterval] = useState(null);
  const [lipSyncSequence, setLipSyncSequence] = useState([]);
  const [currentLipSyncIndex, setCurrentLipSyncIndex] = useState(0);

  // íƒ€ì´í•‘ íš¨ê³¼ interval ref ì¶”ê°€
  const typingIntervalRef = useRef(null);

  // 1. TTS ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡ useEffectë¡œ ìµœì´ˆ 1íšŒë§Œ ë“±ë¡
  useEffect(() => {
    if (!ttsService.isSupported()) return;
    const handleStart = (text, lipSyncSequence) => {
      console.log('TTS ì‹œì‘(ì´ë²¤íŠ¸):', text.substring(0, 50) + '...');
      setIsAiTalking(true);
      setTtsSpeaking(true);

      // ë¦½ì‹±í¬ ì‹œí€€ìŠ¤ ì €ì¥ ë° ì´ˆê¸°í™”
      if (lipSyncSequence && lipSyncSequence.length > 0) {
        setLipSyncSequence(lipSyncSequence);
        setCurrentLipSyncIndex(0);
        console.log('ë¦½ì‹±í¬ ì‹œí€€ìŠ¤ ë°›ìŒ:', lipSyncSequence.length, 'ê°œ ìŒì†Œ');
        console.log('ë¦½ì‹±í¬ ì‹œí€€ìŠ¤ ìƒ˜í”Œ:', lipSyncSequence.slice(0, 5)); // ì²˜ìŒ 5ê°œ ìŒì†Œ í™•ì¸
      } else {
        setLipSyncSequence([]);
        setCurrentLipSyncIndex(0);
        console.log('ë¦½ì‹±í¬ ì‹œí€€ìŠ¤ê°€ ì—†ìŒ');
      }

      // íƒ€ì´í•‘ íš¨ê³¼ ì‹œì‘
      if (typingIntervalRef.current) clearInterval(typingIntervalRef.current);
      let i = 0;
      setDisplayedAiText('');
      typingIntervalRef.current = setInterval(() => {
        setDisplayedAiText(text.slice(0, i + 1));
        i++;
        if (i >= text.length) {
          clearInterval(typingIntervalRef.current);
          typingIntervalRef.current = null;
        }
      }, 30); // íƒ€ì´í•‘ ì†ë„ ì¡°ì ˆ
    };
    const handleEnd = (text) => {
      console.log('TTS ì¢…ë£Œ(ì´ë²¤íŠ¸)');
      setIsAiTalking(false);
      setTtsSpeaking(false);
      setMouthTrigger(0);
      // íƒ€ì´í•‘ íš¨ê³¼ ì¢…ë£Œ ë° ì „ì²´ ë©”ì‹œì§€ í‘œì‹œ
      if (typingIntervalRef.current) {
        clearInterval(typingIntervalRef.current);
        typingIntervalRef.current = null;
      }
      setDisplayedAiText(text); // ì „ì²´ ë©”ì‹œì§€ í•œ ë²ˆì— í‘œì‹œ
    };
    const handleError = (error) => {
      console.error('TTS ì˜¤ë¥˜(ì´ë²¤íŠ¸):', error);
      setIsAiTalking(false);
      setTtsSpeaking(false);
      setMouthTrigger(0);
      if (typingIntervalRef.current) {
        clearInterval(typingIntervalRef.current);
        typingIntervalRef.current = null;
      }
    };
    ttsService.on('start', handleStart);
    ttsService.on('end', handleEnd);
    ttsService.on('error', handleError);
    return () => {
      ttsService.off('start', handleStart);
      ttsService.off('end', handleEnd);
      ttsService.off('error', handleError);
      if (typingIntervalRef.current) {
        clearInterval(typingIntervalRef.current);
        typingIntervalRef.current = null;
      }
    };
  }, []);

  // 2. speakAIMessageì—ì„œ TTS ì¬ìƒ ì§í›„ ë¦½ì‹±í¬ ê°•ì œ ì‹œì‘
  const speakAIMessage = async (message) => {
    try {
      ttsService.stop(); // í•­ìƒ ë¨¼ì € ì¤‘ë‹¨
      if (!isTTSEnabled || !message) return;

      // TTSìš© í…ìŠ¤íŠ¸ ì •ë¦¬ (ì´ëª¨í‹°ì½˜, íŠ¹ìˆ˜ë¬¸ì ì œê±°)
      const cleanedMessage = ttsService.cleanTextForTTS(message);
      if (!cleanedMessage) {
        console.log('TTSë¡œ ì½ì„ ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤:', message);
        return;
      }

      console.log('TTS ì›ë³¸ í…ìŠ¤íŠ¸:', message);
      console.log('TTS ì •ë¦¬ëœ í…ìŠ¤íŠ¸:', cleanedMessage);

      setTtsSpeaking(true); // ë¦½ì‹±í¬ ê°•ì œ ì‹œì‘
      await ttsService.speak(message, { // ì›ë³¸ ë©”ì‹œì§€ ì „ë‹¬ (ì„œë¹„ìŠ¤ì—ì„œ ì •ë¦¬ë¨)
        voice: ttsVoice
      });
    } catch (error) {
      console.error('TTS ì¬ìƒ ì‹¤íŒ¨:', error);
    }
  };

  // 3. ê³ ê¸‰ ë¦½ì‹±í¬ ì‹œìŠ¤í…œ (ìŒì†Œ ê¸°ë°˜)
  useEffect(() => {
    console.log('[LIP SYNC DEBUG] ttsSpeaking:', ttsSpeaking, 'lipSyncSequence.length:', lipSyncSequence.length);

    if (ttsSpeaking && lipSyncSequence.length > 0) {
      console.log('[LIP SYNC] ê³ ê¸‰ ë¦½ì‹±í¬ ì‹œì‘, ì‹œí€€ìŠ¤ ê¸¸ì´:', lipSyncSequence.length);

      // ìŒì†Œ ê¸°ë°˜ ë¦½ì‹±í¬
      const totalDuration = lipSyncSequence[lipSyncSequence.length - 1]?.endTime || 5000; // ê¸°ë³¸ 5ì´ˆ
      const startTime = Date.now();

      console.log('[LIP SYNC] ì´ ì¬ìƒ ì‹œê°„:', totalDuration, 'ms');

      const interval = setInterval(() => {
        const elapsedTime = Date.now() - startTime;
        const currentPhoneme = lipSyncSequence.find(p =>
          elapsedTime >= p.startTime && elapsedTime < p.endTime
        );

        if (currentPhoneme) {
          // ì…ëª¨ì–‘ì— ë”°ë¥¸ mouthTrigger ê°’ ì„¤ì •
          const mouthShapeValues = {
            'closed': 1,
            'slightly_open': 2,
            'open': 3,
            'wide_open': 4,
            'rounded': 5,
            'neutral': 0
          };
          const triggerValue = mouthShapeValues[currentPhoneme.mouthShape] || 0;
          setMouthTrigger(triggerValue);
          console.log('ë¦½ì‹±í¬:', currentPhoneme.phoneme, currentPhoneme.mouthShape, triggerValue, 'ì‹œê°„:', elapsedTime);
        } else {
          // í˜„ì¬ ì‹œê°„ì— í•´ë‹¹í•˜ëŠ” ìŒì†Œê°€ ì—†ìœ¼ë©´ ì¤‘ë¦½
          setMouthTrigger(0);
        }

        // TTS ì¢…ë£Œ ì‹œì  ì²´í¬
        if (elapsedTime >= totalDuration) {
          clearInterval(interval);
          setLipSyncInterval(null);
          setMouthTrigger(0);
          console.log('[LIP SYNC] ë¦½ì‹±í¬ ì¢…ë£Œ');
        }
      }, 50); // 50ms ê°„ê²©ìœ¼ë¡œ ë” ë¹ ë¥´ê²Œ ì—…ë°ì´íŠ¸

      setLipSyncInterval(interval);
      return () => {
        if (interval) clearInterval(interval);
      };
    } else if (ttsSpeaking) {
      console.log('[LIP SYNC] ê¸°ë³¸ ë¦½ì‹±í¬ ì‹œì‘ (fallback)');
      // ê¸°ì¡´ ë‹¨ìˆœ ë¦½ì‹±í¬ (fallback)
      const baseInterval = 200;
      const rateMultiplier = ttsRate || 1.0;
      const lipSyncInterval = Math.max(100, Math.min(400, baseInterval / rateMultiplier));
      console.log('ê¸°ë³¸ ë¦½ì‹±í¬ ê°„ê²© ì„¤ì •:', lipSyncInterval, 'ms (TTS ì†ë„:', rateMultiplier, ')');

      const interval = setInterval(() => {
        setMouthTrigger(prev => prev + 1);
      }, lipSyncInterval);
      setLipSyncInterval(interval);
      return () => {
        if (interval) clearInterval(interval);
      };
    } else {
      setMouthTrigger(0);
      setCurrentLipSyncIndex(0);
      if (lipSyncInterval) {
        clearInterval(lipSyncInterval);
        setLipSyncInterval(null);
      }
    }
  }, [ttsSpeaking, ttsRate, lipSyncSequence]);

  // TTS ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
  const initializeTTSService = () => {
    try {
      console.log('TTS ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹œì‘...');

      // TTS ì§€ì› ì—¬ë¶€ í™•ì¸
      if (!ttsService.isSupported()) {
        console.warn('TTSê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.');
        setIsTTSEnabled(false);
        return;
      }

      // ê¸°ë³¸ ìŒì„± ì„¤ì •
      const voices = ttsService.getVoices();
      if (voices.length > 0) {
        setTtsVoice(voices[0]);
      }

      console.log('TTS ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ');
    } catch (error) {
      console.error('TTS ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
    }
  };

  // ìŒì„± ì„¤ì • ìƒíƒœ í™•ì¸ì„ ìœ„í•œ useEffect
  useEffect(() => {
    if (ttsVoice) {
      console.log('TTS ìŒì„± ìƒíƒœ ì—…ë°ì´íŠ¸ë¨:', ttsVoice.name, '(', ttsVoice.lang, ')');
    }
  }, [ttsVoice]);

  // ìŒì„± ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
  useEffect(() => {
    const updateVoices = () => {
      const voices = window.speechSynthesis.getVoices();
      setVoiceList(voices);
      // ê¸°ë³¸ê°’: ì²« ë²ˆì§¸ í•œêµ­ì–´ ìŒì„±, ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ìŒì„±
      if (!ttsVoice) {
        const koVoice = voices.find(v => v.lang.includes('ko'));
        setTtsVoice(koVoice || voices[0] || null);
      }
    };
    window.speechSynthesis.onvoiceschanged = updateVoices;
    updateVoices();
    return () => {
      window.speechSynthesis.onvoiceschanged = null;
    };
  }, []);

  // ì•„ë°”íƒ€ ì´ˆê¸°í™”
  const initializeAvatars = async () => {
    try {
      console.log('ì•„ë°”íƒ€ ì´ˆê¸°í™” ì‹œì‘');

      // VRM ì•„ë°”íƒ€ íŒŒì¼ ê²½ë¡œ ì„¤ì •
      // VRM íŒŒì¼ì€ avatar_vrm í´ë”ì— ì €ì¥
      const userAvatarUrl = '/avatar_vrm/gb_m_v1.vrm'; // ì‚¬ìš©ì VRM ì•„ë°”íƒ€ (ë‚¨ì„±)
      const aiAvatarUrl = '/avatar_vrm/gb_f_v1.vrm';   // AI VRM ì•„ë°”íƒ€ (ì—¬ì„±)

      console.log('ì‚¬ìš©ì ì•„ë°”íƒ€ URL:', userAvatarUrl);
      console.log('AI ì•„ë°”íƒ€ URL:', aiAvatarUrl);

      setUserAvatar(userAvatarUrl);
      setAiAvatar(aiAvatarUrl);
    } catch (error) {
      console.error('ì•„ë°”íƒ€ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
    }
  };

  // ê°ì • ë¶„ì„ (ë” ì •êµí•œ í‚¤ì›Œë“œ ê¸°ë°˜)
  const analyzeEmotion = (text) => {
    const lowerText = text.toLowerCase();

    // ê¸°ì¨ ê´€ë ¨ í‚¤ì›Œë“œ
    const happyKeywords = [
      'ğŸ˜Š', 'ğŸ˜„', 'ğŸ˜ƒ', 'ğŸ˜', 'ğŸ˜†', 'ğŸ˜…', 'ğŸ˜‚', 'ğŸ¤£', 'ğŸ˜‰', 'ğŸ˜‹', 'ğŸ˜', 'ğŸ¤©', 'ğŸ¥³',
      'ì¢‹ì•„', 'í–‰ë³µ', 'ê¸°ì˜', 'ì¦ê±°', 'ì‹ ë‚˜', 'ì¬ë¯¸ìˆ', 'ì™„ë²½', 'ìµœê³ ', 'ëŒ€ë°•', 'ë©‹ìˆ',
      'ì‚¬ë‘', 'ê°ì‚¬', 'ê³ ë§ˆì›Œ', 'ì¶•í•˜', 'ì„±ê³µ', 'ìŠ¹ë¦¬', 'ë§Œì¡±', 'ê¸°ëŒ€', 'í¬ë§'
    ];

    // ìŠ¬í”” ê´€ë ¨ í‚¤ì›Œë“œ
    const sadKeywords = [
      'ğŸ˜¢', 'ğŸ˜­', 'ğŸ˜”', 'ğŸ˜', 'ğŸ˜Ÿ', 'ğŸ˜•', 'ğŸ™', 'â˜¹ï¸', 'ğŸ˜£', 'ğŸ˜–', 'ğŸ˜«', 'ğŸ˜©', 'ğŸ¥º',
      'ìŠ¬í¼', 'ì•ˆíƒ€ê¹Œì›Œ', 'ìš°ìš¸', 'í˜ë“¤', 'ì§€ì¹˜', 'ì‹¤ë§', 'ì•„ì‰½', 'ë¯¸ì•ˆ', 'ì£„ì†¡', 'í›„íšŒ',
      'ê·¸ë¦¬ì›Œ', 'ì™¸ë¡œì›Œ', 'ë¶ˆì•ˆ', 'ê±±ì •', 'ë‘ë ¤ì›Œ', 'ìƒì²˜', 'ì•„íŒŒ', 'í˜ë“¤ì–´'
    ];

    // í™”ë‚¨ ê´€ë ¨ í‚¤ì›Œë“œ
    const angryKeywords = [
      'ğŸ˜ ', 'ğŸ˜¡', 'ğŸ¤¬', 'ğŸ˜¤', 'ğŸ˜¾', 'ğŸ’¢', 'ğŸ‘¿', 'ğŸ˜ˆ', 'ğŸ¤¯', 'ğŸ˜µ', 'ğŸ¤¬',
      'í™”ë‚˜', 'ì§œì¦', 'ì—´ë°›', 'ë¶„ë…¸', 'í™”ê°€', 'ë¹¡ì³', 'ì—´ë°›', 'ì§œì¦ë‚˜', 'í™”ë‚˜',
      'ì‹«ì–´', 'ë¯¸ì›Œ', 'í˜ì˜¤', 'ì§€ê²¨ì›Œ', 'ë‹µë‹µ', 'ìŠ¤íŠ¸ë ˆìŠ¤', 'ì§œì¦ë‚˜', 'ì—´ë°›ì•„'
    ];

    // ë†€ëŒ ê´€ë ¨ í‚¤ì›Œë“œ
    const surpriseKeywords = [
      'ğŸ˜²', 'ğŸ˜¯', 'ğŸ˜³', 'ğŸ˜±', 'ğŸ¤¯', 'ğŸ˜¨', 'ğŸ˜°', 'ğŸ˜¥', 'ğŸ˜“', 'ğŸ˜¶', 'ğŸ˜', 'ğŸ˜‘',
      'ë†€ë¼', 'ê¹œì§', 'ì–´?', 'ë­?', 'ì§„ì§œ?', 'ì •ë§?', 'ëŒ€ë°•', 'ì™€ìš°', 'ì˜¤ë§ˆì´ê°“',
      'ë¯¿ì„ ìˆ˜ ì—†', 'ìƒìƒë„ ëª»', 'ì˜ˆìƒ ë°–', 'ê°‘ìê¸°', 'ê°‘ì‘ìŠ¤ëŸ½', 'ì¶©ê²©'
    ];

    // ê° ê°ì •ë³„ ì ìˆ˜ ê³„ì‚°
    let scores = {
      happy: 0,
      sad: 0,
      angry: 0,
      surprise: 0
    };

    // í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°
    happyKeywords.forEach(keyword => {
      if (lowerText.includes(keyword)) scores.happy += 1;
    });

    sadKeywords.forEach(keyword => {
      if (lowerText.includes(keyword)) scores.sad += 1;
    });

    angryKeywords.forEach(keyword => {
      if (lowerText.includes(keyword)) scores.angry += 1;
    });

    surpriseKeywords.forEach(keyword => {
      if (lowerText.includes(keyword)) scores.surprise += 1;
    });

    // ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ê°ì • ë°˜í™˜
    const maxScore = Math.max(...Object.values(scores));
    if (maxScore === 0) return 'neutral';

    if (scores.happy === maxScore) return 'happy';
    if (scores.sad === maxScore) return 'sad';
    if (scores.angry === maxScore) return 'angry';
    if (scores.surprise === maxScore) return 'surprise';

    return 'neutral';
  };

  // AI ì•„ë°”íƒ€ ê°ì • ë°˜ì‘ ì‹œìŠ¤í…œ
  const getAIEmotionResponse = (userEmotion, aiMessage) => {
    // ì‚¬ìš©ì ê°ì •ì— ë”°ë¥¸ AI ì•„ë°”íƒ€ ë°˜ì‘
    const emotionResponses = {
      "happy": {
        "primary": "happy",
        "intensity": 0.8,
        "duration": 3000,
        "description": "ì‚¬ìš©ìê°€ ê¸°ë»í•˜ë‹ˆ AIë„ í•¨ê»˜ ê¸°ë»í•©ë‹ˆë‹¤"
      },
      "sad": {
        "primary": "sad",
        "intensity": 0.6,
        "secondary": "caring",
        "duration": 4000,
        "description": "ì‚¬ìš©ìê°€ ìŠ¬í¼í•˜ë‹ˆ AIë„ ê³µê°í•˜ë©° ìœ„ë¡œí•©ë‹ˆë‹¤"
      },
      "angry": {
        "primary": "calm",
        "intensity": 0.7,
        "secondary": "understanding",
        "duration": 3000,
        "description": "ì‚¬ìš©ìê°€ í™”ê°€ ë‚˜ë‹ˆ AIëŠ” ì°¨ë¶„í•˜ê²Œ ì´í•´í•©ë‹ˆë‹¤"
      },
      "fearful": {
        "primary": "caring",
        "intensity": 0.8,
        "secondary": "reassuring",
        "duration": 4000,
        "description": "ì‚¬ìš©ìê°€ ë‘ë ¤ì›Œí•˜ë‹ˆ AIëŠ” ì•ˆì‹¬ì‹œí‚µë‹ˆë‹¤"
      },
      "surprised": {
        "primary": "surprised",
        "intensity": 0.6,
        "secondary": "curious",
        "duration": 2500,
        "description": "ì‚¬ìš©ìê°€ ë†€ë¼ë‹ˆ AIë„ í•¨ê»˜ ë†€ë¼ë©° í˜¸ê¸°ì‹¬ì„ ë³´ì…ë‹ˆë‹¤"
      },
      "disgusted": {
        "primary": "neutral",
        "intensity": 0.5,
        "secondary": "understanding",
        "duration": 2000,
        "description": "ì‚¬ìš©ìê°€ ë¶ˆì¾Œí•´í•˜ë‹ˆ AIëŠ” ì´í•´í•˜ë©° ë‹¤ë¥¸ ì£¼ì œë¡œ ì „í™˜í•©ë‹ˆë‹¤"
      },
      "neutral": {
        "primary": "neutral",
        "intensity": 0.3,
        "duration": 2000,
        "description": "ì‚¬ìš©ìê°€ í‰ì˜¨í•˜ë‹ˆ AIë„ í¸ì•ˆí•œ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤"
      }
    };

    const response = emotionResponses[userEmotion] || emotionResponses["neutral"];

    // AI ë©”ì‹œì§€ ë‚´ìš©ë„ ê³ ë ¤í•˜ì—¬ ê°ì • ì¡°ì •
    const messageEmotion = analyzeEmotion(aiMessage);
    if (messageEmotion !== 'neutral') {
      // ë©”ì‹œì§€ ê°ì •ê³¼ ì‚¬ìš©ì ê°ì •ì„ ì¡°í•©
      if (userEmotion === 'sad' && messageEmotion === 'happy') {
        response.primary = 'caring'; // ìœ„ë¡œí•˜ëŠ” ê¸°ì¨
        response.intensity = 0.7;
      } else if (userEmotion === 'angry' && messageEmotion === 'happy') {
        response.primary = 'calm'; // ì°¨ë¶„í•œ ì´í•´
        response.intensity = 0.6;
      }
    }

    return response;
  };

  // ì–¼êµ´ ì¶”ì  ì½œë°± í•¨ìˆ˜ë“¤
  // ê°ì • ê¸°ë°˜ ëŒ€í™” ì‹œì‘ í•¨ìˆ˜
  const startEmotionBasedConversation = (emotion) => {
    const emotionStarters = {
      "happy": "ê¸°ë» ë³´ì´ì‹œë„¤ìš”! ğŸ˜Š ì–´ë–¤ ì¼ì´ ê·¸ë ‡ê²Œ ê¸°ì˜ê²Œ ë§Œë“  ê±°ì˜ˆìš”?",
      "sad": "ì§€ê¸ˆ ë§ì´ í˜ë“œì‹œê² ì–´ìš”. ğŸ˜” ë¬´ìŠ¨ ì¼ì´ ìˆìœ¼ì…¨ë‚˜ìš”?",
      "angry": "í™”ê°€ ë‚˜ì‹  ê²ƒ ê°™ì•„ ë³´ì—¬ìš”. ğŸ˜¤ ì–´ë–¤ ì¼ì´ ê·¸ë ‡ê²Œ í™”ë‚˜ê²Œ ë§Œë“  ê±°ì˜ˆìš”?",
      "fearful": "ë¬´ì„œìš°ì‹ ê°€ìš”? ğŸ˜° ê±±ì •ë˜ëŠ” ì¼ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”.",
      "surprised": "ë†€ë¼ì‹  ê²ƒ ê°™ì•„ìš”! ğŸ˜² ì–´ë–¤ ì¼ì´ ê·¸ë ‡ê²Œ ë†€ë¼ê²Œ ë§Œë“  ê±°ì˜ˆìš”?",
      "disgusted": "ë¶ˆì¾Œí•˜ì‹  ì¼ì´ ìˆìœ¼ì…¨ë‚˜ìš”? ğŸ˜• ë‹¤ë¥¸ ì´ì•¼ê¸°ë¡œ ê¸°ë¶„ ì „í™˜í•´ë³¼ê¹Œìš”?"
    };

    const starter = emotionStarters[emotion];
    if (starter && messages.length === 0) { // ì²« ëŒ€í™”ì¼ ë•Œë§Œ
      // AIê°€ ë¨¼ì € ë§í•˜ê¸° ì‹œì‘
      ws.current.send(JSON.stringify({
        message: starter,
        emotion: emotion
      }));
      setMessages((prev) => [...prev, { type: 'recv', text: starter }]);
      setCurrentAiMessage(starter);
      setIsAiTalking(true);
    }
  };

  // ì¹´ë©”ë¼ í† ê¸€ í•¸ë“¤ëŸ¬
  const toggleCamera = () => {
    const newCameraState = !isCameraActive;
    setIsCameraActive(newCameraState);

    // ì¹´ë©”ë¼ê°€ ì¼œì§ˆ ë•Œ ìë™ìœ¼ë¡œ ì¹´ë©”ë¼ ì‹œì‘
    if (newCameraState) {
      console.log('ì¹´ë©”ë¼ í™œì„±í™”ë¨');
    } else {
      console.log('ì¹´ë©”ë¼ ë¹„í™œì„±í™”ë¨');
    }
  };

  // ì‹¤ì‹œê°„ ëª¨ë“œ í† ê¸€ í•¸ë“¤ëŸ¬
  const toggleRealTimeMode = () => {
    setIsRealTimeMode(!isRealTimeMode);
    console.log(`ëª¨ë“œ ë³€ê²½: ${!isRealTimeMode ? 'ì‹¤ì‹œê°„' : 'ì•ˆì •í™”'} ëª¨ë“œ`);
  };

  // ìŒì„±ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬
  const handleVoiceResult = (finalText) => {
    console.log('ìŒì„±ì¸ì‹ ìµœì¢… ê²°ê³¼:', finalText);

    // ìë™ì „ì†¡ ì§í›„ì—ëŠ” interim/final ë°˜ì˜ì„ ë§‰ìŒ
    if (blockInterim) return;

    // ìµœì¢… ê²°ê³¼ë¥¼ ëˆ„ì  í…ìŠ¤íŠ¸ì— ì¶”ê°€
    const newAccumulatedText = accumulatedVoiceText + finalText;
    setAccumulatedVoiceText(newAccumulatedText);
    setInput(newAccumulatedText);

    // ë¬µìŒ íƒ€ì´ë¨¸ ë¦¬ì…‹
    if (silenceTimer) {
      clearTimeout(silenceTimer);
    }

    // ìë™ ì „ì†¡ì´ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ ìë™ ì „ì†¡ íƒ€ì´ë¨¸ ì„¤ì •
    if (autoSend) {
      // 2ì´ˆ í›„ ìë™ ì „ì†¡ íƒ€ì´ë¨¸ ì„¤ì •
      const timer = setTimeout(() => {
        if (newAccumulatedText.trim()) {
          console.log('ë¬µìŒ 2ì´ˆ ê²½ê³¼, ìë™ ì „ì†¡:', newAccumulatedText);
          setBlockInterim(true); // interim ë°˜ì˜ ë§‰ê¸°
          setInput(newAccumulatedText);
          sendMessage(newAccumulatedText);
          setAccumulatedVoiceText('');
          // 0.5ì´ˆ í›„ interim ë°˜ì˜ ì¬ê°œ
          setTimeout(() => setBlockInterim(false), 500);
        }
      }, 2000); // 2ì´ˆë¡œ ë³€ê²½

      setSilenceTimer(timer);
    }
  };

  // ìŒì„±ì¸ì‹ ì¤‘ê°„ ê²°ê³¼ ì²˜ë¦¬
  const handleVoiceInterimResult = (interimText) => {
    // ì‚¬ìš©ìê°€ ë§í•˜ê¸° ì‹œì‘í•˜ë©´ TTS ì¤‘ë‹¨
    ttsService.stop();
    console.log('ìŒì„±ì¸ì‹ ì¤‘ê°„ ê²°ê³¼:', interimText);

    // ìë™ì „ì†¡ ì§í›„ì—ëŠ” interim ë°˜ì˜ì„ ë§‰ìŒ
    if (blockInterim) return;

    // ì¤‘ê°„ ê²°ê³¼ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œë§Œ í‘œì‹œ (ëˆ„ì í•˜ì§€ ì•ŠìŒ)
    const displayText = accumulatedVoiceText + interimText;
    setInput(displayText);

    // ë¬µìŒ íƒ€ì´ë¨¸ ë¦¬ì…‹
    if (silenceTimer) {
      clearTimeout(silenceTimer);
    }
  };

  // ìŒì„±ì¸ì‹ on/off í† ê¸€ ë° ì¦‰ì‹œ start/stop
  const handleVoiceRecognitionToggle = async () => {
    if (isVoiceRecognitionEnabled) {
      setIsVoiceRecognitionEnabled(false);
      setIsContinuousRecognition(false);
      if (voiceRecognitionRef.current) {
        voiceRecognitionRef.current.stop();
      }
      // ìŒì„±ì¸ì‹ì´ êº¼ì§ˆ ë•Œ ë§ˆì´í¬ë„ OFFë¡œ í‘œì‹œ
      setPermissionStatus('off');
    } else {
      try {
        // ëª¨ë°”ì¼ ë¸Œë¼ìš°ì €ì—ì„œ ê¶Œí•œ ìš”ì²­ì„ ìœ„í•œ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© í™•ì¸
        if (navigator.userAgent.match(/android|webos|iphone|ipad|ipod|blackberry|iemobile|opera mini/i)) {
          console.log('ëª¨ë°”ì¼ ë¸Œë¼ìš°ì € ê°ì§€ë¨ - ê¶Œí•œ ìš”ì²­ ì¤€ë¹„');

          // ê¶Œí•œì´ ê±°ë¶€ëœ ìƒíƒœë¼ë©´ ë¨¼ì € ê¶Œí•œ ìš”ì²­
          if (permissionStatus === 'denied') {
            const granted = await requestMicrophonePermission();
            if (!granted) {
              alert('ìŒì„±ì¸ì‹ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
              return;
            }
          }
        }

        setIsVoiceRecognitionEnabled(true);
        setIsContinuousRecognition(true);

        if (voiceRecognitionRef.current) {
          await voiceRecognitionRef.current.start();
        }
      } catch (error) {
        console.error('ìŒì„±ì¸ì‹ ì‹œì‘ ì‹¤íŒ¨:', error);
        // ê¶Œí•œ ê±°ë¶€ ì‹œ ìƒíƒœ ë˜ëŒë¦¬ê¸°
        setIsVoiceRecognitionEnabled(false);
        setIsContinuousRecognition(false);
      }
    }
  };

  // ìŠ¤í˜ì´ìŠ¤ë°” ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì¶”ê°€
  useEffect(() => {
    const handleKeyDown = (e) => {
      if (e.code === 'Space' && isContinuousRecognition) {
        e.preventDefault(); // ìŠ¤í˜ì´ìŠ¤ë°” ê¸°ë³¸ ë™ì‘ ë°©ì§€
        stopContinuousRecognition();
      }
    };

    if (isContinuousRecognition) {
      document.addEventListener('keydown', handleKeyDown);
    }

    return () => {
      document.removeEventListener('keydown', handleKeyDown);
    };
  }, [isContinuousRecognition]);

  // ì—°ì† ìŒì„±ì¸ì‹ ì‹œì‘
  const startContinuousRecognition = async () => {
    if (!isVoiceRecognitionEnabled) return;

    setIsContinuousRecognition(true);
    if (voiceRecognitionRef.current) {
      await voiceRecognitionRef.current.start();
    }
  };

  // ì—°ì† ìŒì„±ì¸ì‹ ì¤‘ì§€
  const stopContinuousRecognition = () => {
    setIsContinuousRecognition(false);
    if (voiceRecognitionRef.current) {
      voiceRecognitionRef.current.stop();
    }
  };

  // íŠ¸ë˜í‚¹ ê¸°ëŠ¥ ì œì–´
  const toggleTracking = async () => {
    try {
      if (isTrackingEnabled) {
        // íŠ¸ë˜í‚¹ ì¤‘ì§€
        faceTrackingService.stopCamera();
        setIsTrackingEnabled(false);
        setTrackingStatus('stopped');
        setFaceDetected(false);
        console.log('íŠ¸ë˜í‚¹ ì¤‘ì§€ë¨');
      } else {
        // MediaPipe ì¤€ë¹„ ìƒíƒœ í™•ì¸
        if (!faceTrackingService.isReady) {
          console.log('MediaPipeê°€ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ, ì´ˆê¸°í™” ì‹œë„...');
          await faceTrackingService.initializeMediaPipe();

          // ì´ˆê¸°í™” í›„ ë‹¤ì‹œ í™•ì¸
          if (!faceTrackingService.isReady) {
            alert('MediaPipe ì´ˆê¸°í™” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
            return;
          }
        }

        // íŠ¸ë˜í‚¹ ì‹œì‘
        setTrackingStatus('starting');
        const success = await faceTrackingService.startCamera();

        if (success) {
          setIsTrackingEnabled(true);
          setTrackingStatus('running');

          // íŠ¸ë˜í‚¹ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì„¤ì •
          faceTrackingService.on('faceDetected', () => {
            setFaceDetected(true);
          });

          faceTrackingService.on('faceLost', () => {
            setFaceDetected(false);
          });

          console.log('íŠ¸ë˜í‚¹ ì‹œì‘ë¨');
        } else {
          setTrackingStatus('error');
          alert('íŠ¸ë˜í‚¹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›¹ìº  ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
        }
      }
    } catch (error) {
      console.error('íŠ¸ë˜í‚¹ í† ê¸€ ì‹¤íŒ¨:', error);
      setTrackingStatus('error');
      alert('íŠ¸ë˜í‚¹ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ' + error.message);
    }
  };

  // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ í•¨ìˆ˜
  const requestMicrophonePermission = async () => {
    try {
      console.log('ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì‹œì‘...');

      // ëª¨ë°”ì¼ ë¸Œë¼ìš°ì € ê°ì§€
      const isMobile = /android|webos|iphone|ipad|ipod|blackberry|iemobile|opera mini/i.test(navigator.userAgent.toLowerCase());
      console.log('ëª¨ë°”ì¼ ë¸Œë¼ìš°ì € ê°ì§€:', isMobile);

      // navigator.permissions API ì§€ì› í™•ì¸
      if (navigator.permissions && navigator.permissions.query) {
        try {
          const permission = await navigator.permissions.query({ name: 'microphone' });
          setPermissionStatus(permission.state);
          console.log('í˜„ì¬ ê¶Œí•œ ìƒíƒœ:', permission.state);

          if (permission.state === 'granted') {
            console.log('ë§ˆì´í¬ ê¶Œí•œì´ ì´ë¯¸ í—ˆìš©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
            return true;
          }

          if (permission.state === 'denied') {
            console.log('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
            // ëª¨ë°”ì¼ì—ì„œëŠ” ê¶Œí•œ ì¬ì„¤ì •ì„ ìœ„í•´ ë¸Œë¼ìš°ì € ì„¤ì • ì•ˆë‚´
            if (isMobile) {
              alert('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”:\n\nChrome: ì„¤ì • > ê°œì¸ì •ë³´ ë³´í˜¸ ë° ë³´ì•ˆ > ì‚¬ì´íŠ¸ ì„¤ì • > ë§ˆì´í¬\nSafari: ì„¤ì • > Safari > ë§ˆì´í¬');
            }
            return false;
          }
        } catch (permError) {
          console.log('permissions API ì˜¤ë¥˜:', permError);
        }
      }

      // getUserMediaë¥¼ ì‚¬ìš©í•˜ì—¬ ê¶Œí•œ ìš”ì²­ (ë” êµ¬ì²´ì ì¸ ì˜µì…˜)
      console.log('getUserMedia ê¶Œí•œ ìš”ì²­ ì‹œë„...');
      const constraints = {
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      console.log('getUserMedia ì„±ê³µ, ìŠ¤íŠ¸ë¦¼ íšë“:', stream);

      // ìŠ¤íŠ¸ë¦¼ ì¦‰ì‹œ ì¤‘ì§€
      stream.getTracks().forEach(track => {
        track.stop();
        console.log('ì˜¤ë””ì˜¤ íŠ¸ë™ ì¤‘ì§€:', track.label);
      });

      console.log('ë§ˆì´í¬ ê¶Œí•œì´ í—ˆìš©ë˜ì—ˆìŠµë‹ˆë‹¤.');
      setPermissionStatus('granted');
      return true;

    } catch (error) {
      console.error('ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì‹¤íŒ¨:', error);
      console.error('ì˜¤ë¥˜ ì´ë¦„:', error.name);
      console.error('ì˜¤ë¥˜ ë©”ì‹œì§€:', error.message);

      setPermissionStatus('denied');

      if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
        console.log('ì‚¬ìš©ìê°€ ë§ˆì´í¬ ê¶Œí•œì„ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤.');
        alert('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
        return false;
      }

      if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
        console.log('ë§ˆì´í¬ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        alert('ë§ˆì´í¬ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\në§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.');
        return false;
      }

      if (error.name === 'NotSupportedError' || error.name === 'ConstraintNotSatisfiedError') {
        console.log('ì§€ì›ë˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ ì œì•½ ì¡°ê±´ì…ë‹ˆë‹¤.');
        alert('ì§€ì›ë˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ ì„¤ì •ì…ë‹ˆë‹¤.\n\në‹¤ë¥¸ ë¸Œë¼ìš°ì €ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.');
        return false;
      }

      // ê¸°íƒ€ ì˜¤ë¥˜
      alert(`ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n${error.message}\n\në¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.`);
      return false;
    }
  };

  // ìŒì„±ì¸ì‹ ë²„íŠ¼ í´ë¦­ í•¸ë“¤ëŸ¬
  const handleVoiceRecognitionClick = async () => {
    if (!isVoiceRecognitionEnabled) return;

    if (isContinuousRecognition) {
      stopContinuousRecognition();
    } else {
      await startContinuousRecognition();
    }
  };

  // ì´ë¯¸ì§€ ì²¨ë¶€ í•¸ë“¤ëŸ¬
  const handleImageUpload = (e) => {
    const file = e.target.files && e.target.files[0];
    if (!file) return;
    const allowedExt = ['jpg', 'jpeg', 'png', 'webp'];
    const allowedMime = ['image/jpeg', 'image/png', 'image/webp'];
    const maxSize = 4 * 1024 * 1024;
    const ext = file.name.split('.').pop().toLowerCase();
    if (!allowedExt.includes(ext)) {
      alert('í—ˆìš©ë˜ì§€ ì•ŠëŠ” í™•ì¥ìì…ë‹ˆë‹¤: ' + ext);
      return;
    }
    if (file.size > maxSize) {
      alert('íŒŒì¼ ìš©ëŸ‰ì€ 4MB ì´í•˜ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.');
      return;
    }
    if (!allowedMime.includes(file.type)) {
      alert('í—ˆìš©ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤: ' + file.type);
      return;
    }
    setAttachedImage(file);
    setAttachedImagePreview(URL.createObjectURL(file));
  };

  // ì²¨ë¶€ ì´ë¯¸ì§€ í•´ì œ
  const handleRemoveAttachedImage = () => {
    setAttachedImage(null);
    setAttachedImagePreview(null);
  };

  // ë©”ì‹œì§€ ì „ì†¡ í•¨ìˆ˜ ìˆ˜ì •
  const sendMessage = async (text) => {
    const messageText = text !== undefined ? text : input;
    if (!messageText && !attachedImage) return; // ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´ ì „ì†¡X
    let imageUrl = null;
    if (attachedImage) {
      // ì´ë¯¸ì§€ ì„œë²„ ì—…ë¡œë“œ
      const formData = new FormData();
      formData.append('file', attachedImage);
      formData.append('content', messageText);
      try {
        const res = await axios.post('/chat/api/chat/upload_image/', formData, {
          headers: { 'Content-Type': 'multipart/form-data' },
        });
        if (res.data.status === 'success') {
          imageUrl = res.data.file_url;
        } else {
          alert('ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: ' + (res.data.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'));
          return;
        }
      } catch (err) {
        alert('ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: ' + (err.response?.data?.message || err.message));
        return;
      }
    }
    setMessages(prev => ([
      ...prev,
      {
        type: 'send',
        text: messageText || (imageUrl ? '' : ''),
        imageUrl: imageUrl,
        date: new Date().toISOString(),
      }
    ]));
    setInput('');
    setAttachedImage(null);
    setAttachedImagePreview(null);
    // Gemini(ë°±ì—”ë“œ)ë¡œ ë©”ì‹œì§€/ì´ë¯¸ì§€ ì „ì†¡
    if (ws.current && (messageText || imageUrl)) {
      if (ws.current.readyState === 1) {
        ws.current.send(
          JSON.stringify({
            message: messageText || '',
            imageUrl: imageUrl || '',
          })
        );
      } else {
        alert('ì„œë²„ì™€ì˜ ì—°ê²°ì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.');
        console.warn('WebSocketì´ ì•„ì§ OPEN ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤. í˜„ì¬ ìƒíƒœ:', ws.current.readyState);
      }
    }
  };

  // WebSocket ì—°ê²°
  const connectWebSocket = () => {
    // í˜„ì¬ í˜¸ìŠ¤íŠ¸ì˜ IP ì£¼ì†Œë¥¼ ì‚¬ìš©í•˜ì—¬ WebSocket ì—°ê²°
    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
    const host = window.location.hostname;
    // ë°°í¬ í™˜ê²½ì—ì„œëŠ” í¬íŠ¸ ì—†ì´ ë„ë©”ì¸ë§Œ ì‚¬ìš©
    ws.current = new WebSocket(`${protocol}//${host}/ws/chat/`);

    ws.current.onopen = () => {
      console.log('WebSocket ì—°ê²° ì„±ê³µ');
    };

    ws.current.onmessage = (e) => {
      const data = JSON.parse(e.data);
      setMessages((prev) => [...prev, { type: 'recv', text: data.message }]);
      setCurrentAiMessage(data.message);

      // AIê°€ ì‘ë‹µí•  ë•Œ ì• ë‹ˆë©”ì´ì…˜
      setIsAiTalking(true);

      // TTSë¡œ AI ë©”ì‹œì§€ ì¬ìƒ
      if (isTTSEnabled) {
        speakAIMessage(data.message);
      }

      // AI ê°ì • ë°˜ì‘ ì‹œìŠ¤í…œ ì ìš©
      const aiEmotionResponse = getAIEmotionResponse(userEmotion, data.message);
      console.log('AI ê°ì • ë°˜ì‘:', aiEmotionResponse.description);

      // AI ì•„ë°”íƒ€ ê°ì • ì„¤ì •
      setAiEmotion(aiEmotionResponse.primary);
      setEmotionDisplay(prev => ({ ...prev, ai: aiEmotionResponse.primary }));
      setEmotionCaptureStatus(prev => ({ ...prev, ai: true }));

      // ê°ì • ì§€ì† ì‹œê°„ í›„ neutralë¡œ ë³µê·€
      setTimeout(() => {
        setAiEmotion('neutral');
        setEmotionDisplay(prev => ({ ...prev, ai: 'neutral' }));
        setEmotionCaptureStatus(prev => ({ ...prev, ai: false }));
      }, aiEmotionResponse.duration);
    };

    ws.current.onclose = () => {
      console.log('WebSocket ì—°ê²° ì¢…ë£Œ');
    };
  };

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ íƒ€ì´ë¨¸ ì •ë¦¬ ë° TTS ì¤‘ì§€
  useEffect(() => {
    return () => {
      if (silenceTimer) {
        clearTimeout(silenceTimer);
      }
      // TTS ê°•ì œ ì¤‘ì§€
      ttsService.stop();
    };
  }, [silenceTimer]);

  // í˜ì´ì§€ ì–¸ë¡œë“œ ì‹œ TTS ê°•ì œ ì¤‘ì§€
  useEffect(() => {
    const handleBeforeUnload = () => {
      console.log('í˜ì´ì§€ ì–¸ë¡œë“œ ì‹œ TTS ì¤‘ì§€');
      ttsService.stop();
      // ë¸Œë¼ìš°ì €ì˜ speechSynthesisë„ ì§ì ‘ ì¤‘ì§€
      if (window.speechSynthesis) {
        window.speechSynthesis.cancel();
      }
    };

    const handleVisibilityChange = () => {
      if (document.hidden) {
        console.log('í˜ì´ì§€ ìˆ¨ê¹€ ì‹œ TTS ì¤‘ì§€');
        ttsService.stop();
        if (window.speechSynthesis) {
          window.speechSynthesis.cancel();
        }
      }
    };

    // í˜ì´ì§€ ì–¸ë¡œë“œ ì´ë²¤íŠ¸
    window.addEventListener('beforeunload', handleBeforeUnload);
    // í˜ì´ì§€ ìˆ¨ê¹€/ë³´ì„ ì´ë²¤íŠ¸ (íƒ­ ì „í™˜, ë¸Œë¼ìš°ì € ìµœì†Œí™” ë“±)
    document.addEventListener('visibilitychange', handleVisibilityChange);

    return () => {
      window.removeEventListener('beforeunload', handleBeforeUnload);
      document.removeEventListener('visibilitychange', handleVisibilityChange);
      // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œì—ë„ TTS ì¤‘ì§€
      ttsService.stop();
      if (window.speechSynthesis) {
        window.speechSynthesis.cancel();
      }
    };
  }, []);

  // ì•„ë°”íƒ€ í¬ê¸° ë™ì  ê³„ì‚°
  const avatarSize = useMemo(() => {
    // ìƒë‹¨ 50% ì˜ì—­ì˜ ë†’ì´, ê°€ë¡œëŠ” 1/2 (ì¢Œìš° ì•„ë°”íƒ€)
    const vh = window.innerHeight;
    const vw = window.innerWidth;
    // íŒ¨ë”© ë“± ì—¬ìœ ë¶„ 32px ë¹¼ê³ , ìµœëŒ€ 90vw/2 ì´í•˜ë¡œ ì œí•œ
    const maxAvatarWidth = Math.floor((vw - 32) / 2);
    const maxAvatarHeight = Math.floor((vh * 0.5) - 32);
    return Math.max(80, Math.min(maxAvatarWidth, maxAvatarHeight));
  }, [window.innerWidth, window.innerHeight]);

  // ì…ë ¥ì°½ ref ì¶”ê°€
  const inputRef = useRef(null);

  const [attachedImage, setAttachedImage] = useState(null); // ì²¨ë¶€ ì´ë¯¸ì§€ ìƒíƒœ
  const [attachedImagePreview, setAttachedImagePreview] = useState(null); // ë¯¸ë¦¬ë³´ê¸°ìš©
  const [viewerImage, setViewerImage] = useState(null); // ì´ë¯¸ì§€ ë·°ì–´ ëª¨ë‹¬ ìƒíƒœ

  // ESC í‚¤ë¡œ ì´ë¯¸ì§€ ë·°ì–´ ë‹«ê¸°
  useEffect(() => {
    const handleEsc = (e) => {
      if (e.key === 'Escape') setViewerImage(null);
    };
    if (viewerImage) window.addEventListener('keydown', handleEsc);
    return () => window.removeEventListener('keydown', handleEsc);
  }, [viewerImage]);

  // ì•„ë°”íƒ€ on/off ìƒíƒœ ì¶”ê°€
  const [isUserAvatarOn, setIsUserAvatarOn] = useState(false); // ê¸°ë³¸ê°’ off
  const [isAiAvatarOn, setIsAiAvatarOn] = useState(false); // ê¸°ë³¸ê°’ off

  return (
    <>
      {/* ì´ë¯¸ì§€ ë·°ì–´ ëª¨ë‹¬ */}
      {viewerImage && (
        <div className="image-viewer-modal" onClick={() => setViewerImage(null)}>
          <img src={viewerImage} alt="í™•ëŒ€ ì´ë¯¸ì§€" className="image-viewer-img" onClick={e => e.stopPropagation()} />
          <button className="image-viewer-close" onClick={() => setViewerImage(null)}>âœ–</button>
        </div>
      )}
      <div className="chat-container-with-avatars">
        {/* íƒ€ì´í‹€+ìŒì„±/ì¹´ë©”ë¼/íŠ¸ë˜í‚¹ ë²„íŠ¼ í—¤ë” */}
        <div className="chat-header">
          <div className="chat-title">
            Hearth <span role="img" aria-label="fire">ğŸ”¥</span> Chat
          </div>
          {/* ë²„íŠ¼ ë Œë”ë§ ë¶€ë¶„(ë§ˆì´í¬, ì¹´ë©”ë¼, íŠ¸ë˜í‚¹, ì•„ë°”íƒ€ í† ê¸€) */}
          <div className="header-btn-group">
            <button
              onClick={() => setIsVoiceMenuOpen(true)}
              className={`voice-menu-btn-header${isVoiceMenuOpen ? ' active' : ''}`}
            >
              ğŸ¤
            </button>
            {/* AI ì•„ë°”íƒ€ í† ê¸€ */}
            <button className="icon-btn" onClick={() => setIsAiAvatarOn(v => !v)} title="AI ì•„ë°”íƒ€ í† ê¸€">
              <span role="img" aria-label="ai-avatar" style={{ opacity: isAiAvatarOn ? 1 : 0.3 }}>ğŸ¤–</span>
            </button>
            {/* ì‚¬ìš©ì ì•„ë°”íƒ€ í† ê¸€ + íŠ¸ë˜í‚¹ í†µí•© */}
            <button className="icon-btn" onClick={async () => {
              setIsUserAvatarOn(v => {
                const next = !v;
                setIsTrackingEnabled(next);
                if (next) {
                  // íŠ¸ë˜í‚¹ ì„œë¹„ìŠ¤ ì‹œì‘
                  faceTrackingService.startCamera();
                } else {
                  // íŠ¸ë˜í‚¹ ì„œë¹„ìŠ¤ ì¤‘ì§€
                  faceTrackingService.stopCamera();
                }
                return next;
              });
            }} title="ì‚¬ìš©ì ì•„ë°”íƒ€/íŠ¸ë˜í‚¹ í† ê¸€">
              <span role="img" aria-label="user-avatar" style={{ opacity: isUserAvatarOn ? 1 : 0.3 }}>ğŸ‘¤</span>
            </button>
            {/* ì¹´ë©”ë¼ ë²„íŠ¼ */}
            <button
              onClick={toggleCamera}
              className={`camera-btn-header${isCameraActive ? ' active' : ''}`}
            >
              ğŸ“·
            </button>
          </div>
        </div>
        {/* ì•„ë°”íƒ€ë“¤ì„ ìœ„ìª½ì— ì¢Œìš°ë¡œ ë°°ì¹˜ */}
        <div className="avatar-container" style={{ display: 'flex', flexDirection: 'row', width: '100%', height: '50%', margin: 0, padding: 0 }}>
          {/* 1. ì¹´ë©”ë¼ë§Œ ON */}
          {isCameraActive && !isAiAvatarOn && !isUserAvatarOn && (
            <div style={{ flex: 1, width: '100%', height: '100%' }}>
              <EmotionCamera
                isActive={isCameraActive}
                userAvatar={userAvatar}
                userEmotion={userEmotion}
                isUserTalking={isUserTalking}
                mouthTrigger={mouthTrigger}
                emotionCaptureStatus={emotionCaptureStatus.user}
                enableTracking={false}
                showAvatarOverlay={false}
              />
            </div>
          )}
          {/* 2. AI ì•„ë°”íƒ€ë§Œ ON */}
          {!isCameraActive && isAiAvatarOn && !isUserAvatarOn && (
            <div style={{ flex: 1, width: '100%', height: '100%' }}>
              <RealisticAvatar3D
                avatarUrl={aiAvatar}
                isTalking={isAiTalking}
                emotion={aiEmotion}
                mouthTrigger={mouthTrigger}
                position="left"
                size="100%"
                showEmotionIndicator={true}
                emotionCaptureStatus={emotionCaptureStatus.ai}
              />
            </div>
          )}
          {/* 3. ì‚¬ìš©ì ì•„ë°”íƒ€ë§Œ ON */}
          {!isCameraActive && !isAiAvatarOn && isUserAvatarOn && (
            <div style={{ flex: 1, width: '100%', height: '100%' }}>
              <RealisticAvatar3D
                avatarUrl={userAvatar}
                isTalking={isUserTalking}
                emotion={userEmotion}
                position="right"
                size="100%"
                showEmotionIndicator={true}
                emotionCaptureStatus={emotionCaptureStatus.user}
                enableTracking={isTrackingEnabled}
              />
            </div>
          )}
          {/* 4. ì¹´ë©”ë¼+AI ì•„ë°”íƒ€ ON (ì‚¬ìš©ì ì•„ë°”íƒ€ OFF) */}
          {isCameraActive && isAiAvatarOn && !isUserAvatarOn && (
            <>
              <div style={{ flex: 1, width: '50%', height: '100%' }}>
                <RealisticAvatar3D
                  avatarUrl={aiAvatar}
                  isTalking={isAiTalking}
                  emotion={aiEmotion}
                  mouthTrigger={mouthTrigger}
                  position="left"
                  size="100%"
                  showEmotionIndicator={true}
                  emotionCaptureStatus={emotionCaptureStatus.ai}
                />
              </div>
              <div style={{ flex: 1, width: '50%', height: '100%' }}>
                <EmotionCamera
                  isActive={isCameraActive}
                  userAvatar={userAvatar}
                  userEmotion={userEmotion}
                  isUserTalking={isUserTalking}
                  mouthTrigger={mouthTrigger}
                  emotionCaptureStatus={emotionCaptureStatus.user}
                  enableTracking={false}
                  showAvatarOverlay={false}
                />
              </div>
            </>
          )}
          {/* 5. ì¹´ë©”ë¼+ì‚¬ìš©ì ì•„ë°”íƒ€ ON (AI ì•„ë°”íƒ€ OFF) */}
          {isCameraActive && !isAiAvatarOn && isUserAvatarOn && (
            <div style={{ flex: 1, width: '100%', height: '100%' }}>
              <EmotionCamera
                isActive={isCameraActive}
                userAvatar={userAvatar}
                userEmotion={userEmotion}
                isUserTalking={isUserTalking}
                mouthTrigger={mouthTrigger}
                emotionCaptureStatus={emotionCaptureStatus.user}
                enableTracking={isUserAvatarOn}
                showAvatarOverlay={true}
              />
            </div>
          )}
          {/* 6. ì¹´ë©”ë¼+AI+ì‚¬ìš©ì ì•„ë°”íƒ€ ON */}
          {isCameraActive && isAiAvatarOn && isUserAvatarOn && (
            <>
              <div style={{ flex: 1, width: '50%', height: '100%' }}>
                <RealisticAvatar3D
                  avatarUrl={aiAvatar}
                  isTalking={isAiTalking}
                  emotion={aiEmotion}
                  mouthTrigger={mouthTrigger}
                  position="left"
                  size="100%"
                  showEmotionIndicator={true}
                  emotionCaptureStatus={emotionCaptureStatus.ai}
                />
              </div>
              <div style={{ flex: 1, width: '50%', height: '100%' }}>
                <EmotionCamera
                  isActive={isCameraActive}
                  userAvatar={userAvatar}
                  userEmotion={userEmotion}
                  isUserTalking={isUserTalking}
                  mouthTrigger={mouthTrigger}
                  emotionCaptureStatus={emotionCaptureStatus.user}
                  enableTracking={isUserAvatarOn}
                  showAvatarOverlay={true}
                />
              </div>
            </>
          )}
          {/* 7. ì•„ë¬´ê²ƒë„ ì—†ìŒ (ë¹ˆ ê³µê°„) */}
          {!isCameraActive && !isAiAvatarOn && !isUserAvatarOn && (
            <div style={{ flex: 1, width: '100%', height: '100%' }} />
          )}
        </div>
        {/* ì±„íŒ…ì°½ (ì•„ë˜ìª½), paddingBottom:28 */}
        <div className="chat-section" style={{ height: '50%', margin: 0, padding: 0, width: '100%' }}>
          <div className="chat-container">
            <div className="chat-log" ref={chatScrollRef}>
              {messages.map((msg, idx) => {
                // ë‚ ì§œ/ì‹œê°„ í¬ë§· í•¨ìˆ˜
                const dateObj = msg.date ? new Date(msg.date) : new Date();
                const yyyy = dateObj.getFullYear();
                const mm = String(dateObj.getMonth() + 1).padStart(2, '0');
                const dd = String(dateObj.getDate()).padStart(2, '0');
                const hh = String(dateObj.getHours()).padStart(2, '0');
                const min = String(dateObj.getMinutes()).padStart(2, '0');
                // ë‚ ì§œ/ì‹œê°„ ë°•ìŠ¤ JSX
                const dateTimeBox = (
                  <div className="chat-date-time-box">
                    <div className="chat-date-time-year">{yyyy}-</div>
                    <div className="chat-date-time-md">{mm}-{dd}</div>
                    <div className="chat-date-time-hm">{hh}:{min}</div>
                  </div>
                );
                return (
                  <div
                    key={idx}
                    style={{ display: 'flex', flexDirection: msg.type === 'send' ? 'row-reverse' : 'row', alignItems: 'center' }}
                  >
                    {dateTimeBox}
                    <div
                      className={`chat-bubble ${msg.type === 'send' ? 'sent' : 'received'}`}
                      style={{ marginRight: msg.type === 'send' ? 8 : 0, marginLeft: msg.type === 'send' ? 0 : 8 }}
                    >
                      {/* ì´ë¯¸ì§€+í…ìŠ¤íŠ¸ ì¡°í•© ì¶œë ¥ */}
                      {msg.imageUrl && (
                        <img
                          src={msg.imageUrl}
                          alt="ì²¨ë¶€ ì´ë¯¸ì§€"
                          className="attached-image-thumb"
                          style={{ cursor: 'pointer' }}
                          onClick={() => setViewerImage(msg.imageUrl)}
                        />
                      )}
                      {msg.text && (
                        <div>{msg.type === 'recv' && idx === messages.length - 1 && isAiTalking ? displayedAiText : msg.text}</div>
                      )}
                    </div>
                  </div>
                );
              })}
            </div>
            <div className="chat-input-area">
              {/* ì²¨ë¶€ ì´ë¯¸ì§€ ì¸ë„¤ì¼+X ë²„íŠ¼ì„ textarea ë°”ë¡œ ìœ„ì— ìœ„ì¹˜ */}
              {attachedImagePreview && (
                <div className="attached-image-preview-box">
                  <img src={attachedImagePreview} alt="ì²¨ë¶€ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°" className="attached-image-thumb" />
                  <button onClick={handleRemoveAttachedImage} className="attached-image-remove-btn">âœ–</button>
                  {/* <span className="attached-image-label">ì´ë¯¸ì§€ ì²¨ë¶€ë¨</span> */}
                </div>
              )}
              <div className="input-controls">
                <div className="chat-input-box">
                  {/* ì´ë¯¸ì§€ ì²¨ë¶€ ë²„íŠ¼ (ì™¼ìª½) */}
                  <label htmlFor="chat-image-upload" className="image-upload-btn-side">
                    <input
                      id="chat-image-upload"
                      type="file"
                      accept="image/*"
                      style={{ display: 'none' }}
                      onChange={handleImageUpload}
                    />
                    <span className="image-upload-btn-icon">ğŸ“¤</span>
                  </label>
                  <textarea
                    ref={inputRef}
                    placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
                    value={input}
                    onChange={(e) => setInput(e.target.value)}
                    onKeyDown={(e) => {
                      if (e.key === 'Enter' && !e.shiftKey) {
                        e.preventDefault();
                        sendMessage();
                      }
                    }}
                    onInput={e => {
                      e.target.style.height = 'auto';
                      e.target.style.height = e.target.scrollHeight + 'px';
                    }}
                    className="input-flex chat-textarea"
                    rows={1}
                  />
                  <button onClick={() => sendMessage()} className="unified-btn">ğŸ”¥</button>
                </div>
              </div>
            </div>
          </div>
        </div>
        {/* ìŒì„± ë©”ë‰´ ëª¨ë‹¬ */}
        <Modal open={isVoiceMenuOpen} onClose={() => setIsVoiceMenuOpen(false)}>
          {/* TTS ê´€ë ¨ ê¸°ëŠ¥ ë°•ìŠ¤ */}
          <div className="voice-modal-tts-box">
            <div className="voice-modal-section">
              <button
                onClick={() => setIsTTSEnabled(!isTTSEnabled)}
                className={`tts-toggle ${isTTSEnabled ? 'active' : ''}`}
                title={isTTSEnabled ? 'TTS ë„ê¸°' : 'TTS ì¼œê¸°'}
              >
                {isTTSEnabled ? 'ğŸ”Š TTS ì¼œì§' : 'ğŸ”‡ TTS êº¼ì§'}
              </button>
            </div>
            <div className="voice-modal-section">
              <div style={{ marginBottom: '10px', fontSize: '12px' }}>
                <div style={{ marginBottom: '5px' }}>
                  ì†ë„: {ttsRate}x | ìŒì¡°: {ttsPitch}
                </div>
                {/* TTS ì†ë„ ë“œë¡­ë‹¤ìš´ */}
                <label htmlFor="tts-rate-select" style={{ marginRight: '8px' }}>ì†ë„:</label>
                <select
                  id="tts-rate-select"
                  value={ttsRate}
                  onChange={e => {
                    const val = Number(e.target.value);
                    setTtsRate(val);
                    ttsService.setRate(val);
                  }}
                  style={{ marginRight: '16px', fontSize: '12px' }}
                >
                  {Array.from({ length: 21 }, (_, i) => (1.0 + i * 0.05).toFixed(2)).map(val => (
                    <option key={val} value={Number(val)}>{val}</option>
                  ))}
                </select>
                {/* TTS ìŒì¡° ë“œë¡­ë‹¤ìš´ */}
                <label htmlFor="tts-pitch-select" style={{ marginRight: '8px' }}>ìŒì¡°:</label>
                <select
                  id="tts-pitch-select"
                  value={ttsPitch}
                  onChange={e => {
                    const val = Number(e.target.value);
                    setTtsPitch(val);
                    ttsService.setPitch(val);
                  }}
                  style={{ fontSize: '12px' }}
                >
                  {Array.from({ length: 21 }, (_, i) => (1.0 + i * 0.05).toFixed(2)).map(val => (
                    <option key={val} value={Number(val)}>{val}</option>
                  ))}
                </select>
              </div>
              <div style={{ marginBottom: '10px' }}>
                <label htmlFor="voice-select-modal" style={{
                  display: 'block',
                  marginBottom: '5px',
                  fontSize: '12px',
                  fontWeight: 'bold'
                }}>
                  ìŒì„± ì„ íƒ:
                </label>
                <select
                  id="voice-select-modal"
                  value={ttsVoice ? ttsVoice.name : ''}
                  onChange={e => {
                    const selected = voiceList.find(v => v.name === e.target.value);
                    setTtsVoice(selected);
                    console.log('ì„ íƒëœ ìŒì„±:', selected?.name, '(', selected?.lang, ')');
                  }}
                  style={{
                    width: '100%',
                    padding: '5px',
                    borderRadius: '3px',
                    border: '1px solid #ccc',
                    fontSize: '12px'
                  }}
                >
                  {voiceList.length === 0 ? (
                    <option value="">ìŒì„± ëª©ë¡ ë¡œë”© ì¤‘...</option>
                  ) : (
                    voiceList.map((voice, idx) => (
                      <option key={voice.name + idx} value={voice.name}>
                        {voice.name} ({voice.lang})
                      </option>
                    ))
                  )}
                </select>
              </div>
            </div>
          </div>
          {/* ìŒì„±ì¸ì‹/ìë™ì „ì†¡/ë§ˆì´í¬ ê¶Œí•œ í† ê¸€ ë²„íŠ¼ í•œ ì¤„ ë°°ì¹˜ */}
          <div className="voice-modal-section" style={{ display: 'flex', gap: '10px', alignItems: 'center' }}>
            {/* ìŒì„±ì¸ì‹ on/off í† ê¸€ */}
            <button
              onClick={handleVoiceRecognitionToggle}
              className={`mic-toggle ${isVoiceRecognitionEnabled ? 'active' : ''}`}
              title={isVoiceRecognitionEnabled ? 'ìŒì„±ì¸ì‹ ë„ê¸°' : 'ìŒì„±ì¸ì‹ ì¼œê¸°'}
            >
              {isVoiceRecognitionEnabled ? 'ğŸ¤ ìŒì„±ì¸ì‹ ì¼œì§' : 'ğŸ”‡ ìŒì„±ì¸ì‹ êº¼ì§'}
            </button>
            {/* ìë™ì „ì†¡ í† ê¸€ */}
            <button
              onClick={() => setAutoSend(!autoSend)}
              className={`auto-send-toggle ${autoSend ? 'active' : ''}`}
              title={autoSend ? 'ìë™ì „ì†¡ ë„ê¸°' : 'ìë™ì „ì†¡ ì¼œê¸°'}
            >
              {autoSend ? 'ğŸš€ ìë™ì „ì†¡ ì¼œì§' : 'âœï¸ ìë™ì „ì†¡ êº¼ì§'}
            </button>
          </div>
          {/* VoiceRecognition ì „ì²´ UI ë³µêµ¬ */}
          <div className="voice-modal-section">
            <VoiceRecognition
              ref={voiceRecognitionRef}
              enabled={isVoiceRecognitionEnabled}
              continuous={isContinuousRecognition}
              onResult={handleVoiceResult}
              onInterimResult={handleVoiceInterimResult}
              onStart={() => setIsContinuousRecognition(true)}
              onStop={() => setIsContinuousRecognition(false)}
              onAutoSend={(finalText) => {
                console.log('onAutoSend (chat_box.jsx) í˜¸ì¶œ, finalText:', finalText);
                if (autoSend && finalText && finalText.trim()) {
                  // setInput(finalText); // inputì°½ì—ë§Œ ë°˜ì˜, ì‹¤ì œ ì „ì†¡ì—ëŠ” ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ì£¼ì„ì²˜ë¦¬
                  sendMessage(finalText);
                  setAccumulatedVoiceText('');
                }
              }}
            />
          </div>
        </Modal>
      </div>
    </>
  );
};

export default ChatBox;
